In diesem Kapitel werden die wichtigen Grundlagen erläutert, die nötig sind, um das Problem der mangelhaften Softwaredokumentation zu lösen.  Dazu  wird der Begriff \enquote{Softwaredokumentation} genauer definiert (Kapitel \ref{chapter:documentation}). Anschließend gibt es eine Einführung in Javadoc, dessen Analyse der Schwerpunkt dieser Bachelorarbeit ist (Kapitel \ref{chapter:javadoc}). In Kapitel \ref{chapter:code_smell} wird eine Einführung in Code-Smells gegeben. Anschließend erfolgt eine Einführung in TypeScript und Node.js, welche zur Entwicklung des Tools verwendet werden (Kapitel \ref{js_ts_node}). Um später das Parsing von Quelltextdateien zu ermöglichen, wird zudem in Kapitel \ref{chapter:antlr} die Bibliothek \textit{ANTLR4} vorgestellt. Im darauffolgenden Kapitel \ref{chapter:github_actions} wird die \ac{CI/CD}-Plattform \textit{GitHub Actions} präsentiert, die genutzt werden soll, um die Dokumentationsqualität regelmäßig zu messen. In Kapitel \ref{chapter:related_tools} werden weitere Tools vorgestellt, die fehlerhafte Dokumentationen erkennen können. Zuletzt werden in Kapitel \ref{chapter:related_science} wissenschaftliche Arbeiten zusammengefasst, die sich ebenfalls mit der Thematik \enquote{Softwaredokumentation} befassen. 
 

\hfill
\section{Softwaredokumentation}\label{chapter:documentation}
Um den Begriff \enquote{Softwaredokumentation} zu definieren, sollte zunächst der Begriff \enquote{Dokumentation} definiert werden. Das IEEE  definiert diesen Begriff als jede textliche oder bildliche Information, welche Aktivitäten, Anforderungen, Abläufe oder Ergebnisse beschreibt, definiert, spezifiziert, berichtet oder zertifiziert \cite[S.~28]{IEEEStandardGlossaryofSoftwareEngineeringTerminology}. Somit beschreibt eine Dokumentation, wie eine Komponente aufgebaut ist oder wie sie sich verhält.

Diese abstrakte Definition lässt sich so auf Softwareentwicklung übertragen. In \cite[S.~125]{Softwaredocumentationandstandards} wird Softwaredokumentation als eine Sammlung von technischen Informationen dargestellt, die für Menschen lesbar sind und welche die Funktionen, Benutzung oder das Design eines Softwaresystems beschreiben. So beschreibt Donald E. Knuth in \cite[S.~97]{LiterateProgramming}, dass die Hauptaufgabe beim Programmieren nicht sein sollte, einem Computer zu erklären, was er machen sollte, sondern anderen Menschen zu erklären, was der Computer machen sollte. Beispiele für Softwaredokumentation sind Kommentare,  UML-Diagramme, Readme-Dateien oder Handbücher.

Im Kontext dieser Bachelorarbeit sollen allerdings nur bestimmte Arten der Softwaredokumentation betrachtet werden, da eine umfassende Betrachtung innerhalb der vorgegebenen Zeit nicht möglich ist.  Zwar wären Readme-Dateien oder UML-Diagramme für eine Bewertung auch interessant, allerdings sind diese nicht so stark mit dem dazugehörigen Code verknüpft, sondern befinden sich in externen Dateien, sodass eine Verarbeitung ungleich schwieriger wäre.

Aus diesem Grunde konzentriert sich diese Bachelorarbeit nur auf Kommentare. Studien zeigen, dass Kommentare eine hohe Relevanz in der Softwareentwicklung haben, sodass eine Analyse der Kommentare eine gute Annäherung an die tatsächliche Qualität der Dokumentation geben kann \cite[S.~71]{AStudyoftheDocumentationEssentialtoSoftwareMaintenance}. Dabei sollen nicht alle Kommentare betrachtet werden, sondern nur eine bestimmte Kategorie von Kommentaren, die besonders leicht verarbeitbar sind, sodass aus ihnen viele Informationen extrahiert werden können und die Bewertung dadurch genauer werden kann. 

Für diese Bachelorarbeit werden daher nur bestimmte Inline-Kommentare im Quellcode betrachtet, die ein Spezialfall von mehrzeiligen Kommentaren sind.
Diese Kommentare werden wie normale Kommentare erkannt und werden daher nicht Bestandteil des kompilierten Programms. Dennoch haben diese spezifischen Kommentare aber eine bestimmte Struktur, die eine leichtere Verarbeitung durch Programme ermöglicht und gleichzeitig trotzdem für Menschen lesbar bleibt. Diese Kommentare stehen als Präfix vor einer bestimmten Komponente und werden ihr so eindeutig zugeordnet. Im Folgenden werden diese Kommentare auch \textbf{strukturierte Kommentare} genannt. Ein Beispiel für solche strukturierte Kommentare ist Javadoc. 







\section{Javadoc}\label{chapter:javadoc}
Javadoc \cite{HowtoWriteDocCommentsfortheJavadocTool} ist ein Tool zur Generierung von Dokumentationen, das sich als de facto Standard für Dokumentationen in der Programmiersprache Java etabliert hat \cite[S.~249]{JavadocViolationsandTheirEvolutioninOpen-SourceSoftware}.  Javadoc verwendet spezielle Java-Kommentare, die an bestimmten Stellen im Quellcode eingefügt werden und daher bei der Kompilation nicht berücksichtigt werden. Ein Javadoc-Block beschreibt immer ein bestimmtes Modul (z. B. eine Klasse, Methode oder Feld). Es beginnt mit der Zeichenkette \enquote{/**}, wobei die ersten beiden Zeichen \enquote{/*} den Beginn eines mehrzeiligen Kommentars in Java einläuten, und endet mit \enquote{*/}. Durch das zusätzliche \enquote{*} unterscheidet sich ein Javadoc-Kommentar von einem normalen mehrzeiligen Kommentar, der zwar zur Kommentierung eines Blocks verwendet werden kann, aber vom Javadoc-Tool ignoriert wird und daher einen geringeren Mehrwert hat. 


		\begin{figure}[ht!]
			\lstinputlisting
			[caption={Beispielhafter Javdoc-Block für einfache Methode},
			label={lst:simple_javadoc},
			captionpos=b,language=java, basicstyle=\footnotesize, tabsize=1, showstringspaces=false,  numbers=left]
			{figures/chapter2/ternary.java}
		\end{figure}

Listing \ref{lst:simple_javadoc} zeigt beispielhaft, wie eine Methode mittels Javadoc dokumentiert werden kann.
\begin{comment}Zunächst wird der Zweck der Methode beschrieben, anschließend wird jeder Parameter erläutert (Z.~3--5). Dabei sollte in komplexeren Fällen auch erklärt werden, welche Werte gültig für den Parameter sind. Danach folgt eine Beschreibung des Rückgabewertes (Z.~6), welche am besten auch jeden möglichen Fall abdeckt. Um bestimmte Infomrationen \enquote{\{@code ...\}}, der auch kann auf einen Parameter referenziert werden. Mit diesen Informationen kann der Programmierer leicht überblicken, wie eine Methode genutzt werden, sodass die Einarbeitungszeit und die Fehleranfälligkeit reduziert werden kann.  
\end{comment}
Zunächst sollte am Anfang des Blocks eine generelle Zusammenfassung der Komponente stehen  (Z.~2). Danach können sogenannte Block-Tags (-Tags z.~dt. Auszeichner), die mit dem \enquote{@}-Zeichen beginnen, benutzt werden. Diese beschreiben wiederum einen bestimmten Teilbereich einer Komponente. In den Zeilen 3 bis 5 werden alle Parameter einer Methode beschrieben. Auch der Rückgabewert einer Methode kann so genauer erläutert werden (Z.~6). Mittels sogenannter Inline-Tags können zudem Abschnitte in einer Dokumentation besonders gekennzeichnet werden. Hier wird mittels \enquote{\{@code ...\}} deutlich gemacht, dass das Wort \enquote{condition} nicht als Wort zu verstehen ist, sondern als Verweis auf den Parameter \textit{condition} verstanden werden soll. Es ist zudem Konvention, dass jede Zeile in einem Javadoc-Block mit einem Asterisk beginnt. 

In der folgenden Auflistung werden beispielhaft einige Javadoc-Tags aufgelistet und beschrieben. Inline-Tags werden mit geschweiften Klammern umschlossen:
\begin{description}
         \item[@param]  Beschreibt einen Parameter, benötigt den Parameternamen als Argument
         \item[@return]  Beschreibt den Rückgabewert der Methode, sofern er existiert 
         \item[@throws] Beschreibt welche Ausnahmen diese Methode werfen kann und möglichst unter welchen Umständen dies passiert, benötigt den Namen der Ausnahme. Für mehrere Ausnahmen sollte dieser Tag entsprechend wiederholt werden 
         \item[@deprecated] Falls diese Methode veraltet ist und nicht mehr verwendet werden sollte, kann hier eine Alternative beschrieben werden
         \item[@see] Ermöglicht einen Verweis auf einer anderen Komponente, um die Navierbarkeit zu erleichtern, beim Rendering werden diese Verweise in einem separaten Abachnitt angezeigt
         \item[\{@code\}] Kann verwendet werden, um Quellcode in Dokumentationen einzubinden
         \item [\{@link\}] Ermöglicht einen  Verweis auf eine andere Komponente, um so Navierbarkeit zu erleichtern, wird an dieser Stelle in einem Link umgewandelt
        
\end{description}



Diese Javadoc-Blöcke können dann von dem gleichnamigen Tool in eine \ac{HTML}-Datei umgewandelt werden und ermöglichen den Entwicklern damit einen komfortablen Überblick über alle Komponenten eines Moduls. Zudem können Javadoc-Blöcke ebenfalls \ac{HTML}-Inhalte besitzen, die dann von Javadoc in die \ac{HTML}-Datei übernommen werden, sodass der Entwickler beispielsweise Tabellen zur übersichtlichen Präsentation  von Informationen verwenden kann. 

Eine \ac{IDE} kann die Informationen auslesen und dann beispielsweise bei der Autovervollständigung nutzen, um den Entwickler beim Schreiben des Programmcodes zu unterstützen. So kann sich ein Programmierer auch in einer fremden Programmbibliothek leichter zurechtfinden.

Ein Javadoc-Kommentar wird vererbt und muss daher für eine abgeleitete Klasse nicht neu geschrieben oder redundant geklont werden. Dies ist sinnvoll, da abgeleitete Klassen einen Vertrag erfüllen müssen, der bei einer guten Dokumentation auch schon in der Javadoc-Dokumentation beschrieben wird. Auch bei Methoden, die aufgrund einer Schnittstelle implementiert werden müssen, ist eine Neudefinition des Javadoc-Kommentars unnötig. Falls sinnvoll, kann aber dennoch ein eigener Javadoc-Kommentar erstellt werden, der allerdings den Kommentar der Quelle vollständig ersetzt. Mit \enquote{@inheritDoc} kann der ursprüngliche Kommentar aber trotzdem eingefügt werden.

Nachfolgend ist ein Auszug von empfehlenswerten Tipps von der Oracle-Webseite, die beim Schreiben von Javadoc beachtet werden sollten \cite{HowtoWriteDocCommentsfortheJavadocTool}:
\begin{itemize}
    \item Nicht in jedem Fall vollständige Sätze verwenden, aber klar formulieren, was die Aufgabe einer Komponente ist
    \item In der dritten und nicht in der zweiten Person schreiben
    \item Nicht repetitiv sein. Ein Kommentar, der im Wesentlichen nur den Namen einer Komponente wiedergibt, hat keinen Mehrwert
    \item  Beschreibungen von Methoden sollten mit einem Verb beginnen
    \item Keine lateinischen Ausdrücke wie \enquote{e.g.}, \enquote{aka} oder \enquote{i.e.} verwenden
    \item Bei einem Verweis auf das aktuelle Objekt sollte das spezifische \textit{this} statt des allgemeineren \textit{the} verwendet werden, bspw. \enquote{opens the connection of \textbf{this} object} statt \enquote{opens the connection of \textbf{the} object}
    \item Bezeichner sollten mit \enquote{<code></code>} umschlossen werden, um deutlich zu machen, dass dies eine andere Komponente ist
    \item Der Kommentar sollte eventuelle Unterschiede unter verschiedene Plattformen erläutern
    \item Die Dokumentation sollte erläutern, wie sich die Komponente in Randfällen verhält
    
\end{itemize}

Für andere Programmiersprachen gibt es vergleichbare Werkzeuge, die ähnliche Funktionen anbieten und bei denen die Dokumentationen mit einer relativ ähnlichen Syntax erstellt werden. Dazu gehören beispielsweise \textit{Doxygen} \cite{doxygen} für C++-Programme oder \textit{Docstring} \cite{docstring} für Python-Programme. 
\section{Code-Smells}\label{chapter:code_smell}
Der Begriff \enquote{Code-Smell} (z.~dt. übel riechender Code)  wurde von Kent Beck in \cite[S.~71 ff.]{fowler2019refactoring}  vorgeschlagen, um Quellcode zu beschreiben, bei dem Refactoring (z.~dt. Restrukturierung) sinnvoll ist. Bestimmte Strukturen im Quellcode deuten darauf hin, dass der Code verbessert werden sollte, da ansonsten die zukünftige Wartbarkeit des Codes verringert wird. Beispiele sind schlecht gewählte Namen für Variablen oder Methoden, duplizierter Code, lange Methoden oder globale Daten. In bestimmten Situationen werden Kommentare ebenfalls als Code-Smell klassifiziert, da sie auf komplizierten  Code hindeuten können oder der Name einer Komponente schlecht gewählt wurde. Daher sollte geprüft werden, ob nach einem Refactoring die Kommentare noch notwendig sind.

Nach \cite[S.~249--250]{JavadocViolationsandTheirEvolutioninOpen-SourceSoftware} kann eine mangelhafte Dokumentation als Code-Smell bezeichnet werden, da sie die Wartbarkeit der Software beeinträchtigen kann. Dies gilt besonders, wenn die Dokumentation vom Code abweicht und damit bei den Entwicklern zu Verwirrung führt. Eine fehlerhaft dokumentierte Methode, bei der beispielsweise ein Parameter nicht dokumentiert ist, deutet stark auf Code-Smells hin, da der Code von der Dokumentation divergiert. Zudem kann eine \ac{IDE} die Informationen von strukturierten Kommentaren nutzen, um beispielsweise dem Benutzer einer Methode Hinweise zur Benutzung zu geben. Dies ist bei normalen Kommentaren nicht möglich. 

\section{JavaScript, Node und TypeScript}\label{js_ts_node}
Das Tool wird mittels der \textit{Node.js}-Bibliothek und TypeScript entwickelt.
In diesem Abschnitt werden daher die grundlegenden Programmiersprachen und Bibliotheken vorgestellt, die zur Entwicklung des Tools als Desktopanwendung notwendig sind. Außerdem wird begründet, warum TypeScript und \enquote{Node.js} für die Entwicklung des Tools verwendet wird. 
\subsubsection{JavaScript}
JavaScript \cite{javascript} ist eine dynamisch typisierte Programmiersprache, die sich als de facto Standard  für Browserskripte etabliert hat, die auf dem Client (z.~dt. Klienten) ausgeführt werden. Zum Beispiel lassen sich mittels JavaScript Webseiten dynamisieren, Eingaben von Formularen validieren oder nachträglich Daten von anderen Servern laden. 

Die Syntax von JavaScript basiert wie bei der Programmiersprache Java auf C, dennoch sollten Java und JavaScript nicht verwechselt werden. Die eingangs erwähnte dynamische Typisierung bedeutet im Gegensatz zur statischen Typisierung, dass eine Variable anders als in Java keinen fixen Datentyp hat, sondern der Datentyp sich stets nach dem aktuellen Wert richtet. Eine Variable \textit{foo} kann mit dem Befehl \textit{ let foo = true} deklariert werden und ist dann vom Datentyp \textit{Bool}. Daraufhin kann der gleichen Variable eine Zeichenkette zugewiesen werden, sodass die Variable nun vom Datentyp \textit{String} ist. Durch die dynamische Typisierung ist der Programmierer flexibler, jedoch zeigt eine Studie, dass die Softwarequalität bei Projekten mit statischer Typisierung etwas besser ist als mit dynamischer Typisierung \cite[S.~155ff.]{Ray2014}.

\subsubsection{TypeScript}
TypeScript \cite{typescript} ist eine auf JavaScript aufbauende Programmiersprache, die JavaScript um statische Typisierung ergänzt. Jeder JavaScript-Code ist gültiger TypeScript-Code, sodass TypeScript als Obermenge von JavaScript angesehen werden kann. Der TypeScript-Code kann nicht direkt ausgeführt werden, sondern wird in gültiges JavaScript transkribiert, sodass er von einem Client mit JavaScript-Unterstützung ausgeführt werden kann. 

In TypeScript können Typannotationen verwendet werden, die den Datentyp einer Variablen festlegen. Eine Variable \textit{foo} kann in TypeScript dem Befehl \textit{let foo:boolean=true} als \textit{Boolean} deklariert werden. Durch die Angabe \enquote{:boolean} ist der Datentyp fix und kann nicht geändert werden. Eine Zuweisung einer Zeichenkette zu \textit{foo} würde TypeScript mit einer Fehlermeldung quittieren. Auch viele Funktionen, die in objektorientierten Programmiersprachen verbreitet sind, wie z.~B. Schnittstellen, generische Typen oder Namensräume werden von TypeScript unterstützt und helfen so dabei, komplexere Programme zu schreiben. Aus diesen Gründen wird TypeScript für die Entwicklung des Projektes verwendet, denn eine Verwendung von statischen Typen und anderen objektorientierten Funktionen ermöglicht eine bessere Abstraktion der einzelnen Schritte (Traversierung, Parsing, Anwendung der Metriken etc.). 

\subsubsection{Node.js}
Die Bibliothek  \textit{Node.js} \cite{nodejs} ist eine beliebte Bibliothek, um JavaScript-Programme nicht nur im Browser, sondern auch als eigenständige Applikation zu entwickeln. Dadurch haben sie im Gegensatz zu den klassischen Browser-Skripten freien Zugriff auf das Dateisystem und Netzwerkfunktionen.  Die Bibliothek läuft auf den meisten Systemen und  wird von GitHub Actions nativ unterstützt. Außerdem gibt es über den Paketmanager \textit{NPM} eine große Auswahl an kleineren Bibliotheken, die kleinere Probleme lösen können und damit Entwicklungsaufwand bei Aufgaben sparen, welche nicht im Kernbereich dieser Bachelorarbeit liegen. Folglich wurde diese Bibliothek als Fundament für die Entwicklung des Tools genutzt. 
\section{ANTLR4}\label{chapter:antlr}
Um die Java-Dateien zu parsen (siehe Kapitel \ref{chapter:antlr4_impl}), wird die Bibliothek ANTLR4 \cite{ANTLR} verwendet, die kostenlos verfügbar ist. Diese Bibliothek kann nicht nur viele Programmiersprachen, sondern auch selbst geschriebene Sprachen parsen, sofern eine passende Grammatik verfügbar ist. 

Eine andere Möglichkeit zum Parsen der Java-Dateien ist die NPM-Bibliothek \enquote{java-parser} \cite{Java-parser}. Dies hätte den Vorteil, dass das Parsen, welches nicht der Hauptfokus dieser Bachelorarbeit ist, ausgelagert wird und so Fehler vermieden werden können. Allerdings kann diese Bibliothek nicht die Verbindung zwischen einer Komponente und dem dazugehörigen Javadoc-Block herstellen, sodass eine Benutzung dieser Bibliothek die Arbeit deutlich erschwert hätte. Daher wird  \textit{ANTLR4} verwendet. Außerdem besteht die Möglichkeit, eine eigene Grammatik für Java zu schreiben, da die originale Grammatik für Java sämtliche Kommentare ignoriert. Da dies jedoch deutlich komplizierter war als erwartet, wird die von vielen Entwicklern geschriebene Grammatik verwendet.

\subsubsection{Lexer und Parser}
Eine Grammatik für Programmiersprachen besteht immer aus einer Lexer-Grammatik und einer Parser-Grammatik, die jeweils vom Lexer bzw. Parser in dieser Reihenfolge verarbeitet werden, um so eine Baumstruktur einer Quellcodedatei zu erhalten. Der Lexer erstellt aus einer Quellcodedatei eine Liste von Tokens. Dabei ist ein Token eine Gruppierung von einem oder mehreren Zeichen, die eine weitergehende Bedeutung haben. Beispielsweise können Schlüsselwörter einer Programmiersprache oder Operatoren als Token klassifiziert werden. Diese Tokens sind grundsätzlich kontextunabhängig, das heißt für die gleiche Zeichenkette wird das gleiche Token verwendet. Jeder Token wird durch seine Zeichenkette und den Tokentyp klassifiziert.

Listing \ref{lst:lexer_example} zeigt zur Verdeutlichung der Syntax eine Zeile aus der Lexer-Grammatik. 
		\begin{figure} [htbp!]
			\lstinputlisting
			[caption={Beispielhafte Syntax vom Lexer},
			label={lst:lexer_example},
			captionpos=b, basicstyle=\footnotesize, tabsize=2, showstringspaces=false,  numbers=left,language=ANTLR]
			{figures/chapter4/lexer_example.g4}
		\end{figure}

Eine Zeile in der Lexer-Grammatik beginnt mit dem Namen eines Tokens, gefolgt von einem Doppelpunkt und dann einem regulären Ausdruck, der dieses Token beschreibt. In der beispielhaften Lexer-Grammatik wird ein Javadoc-Kommentar definiert, das mit \enquote{/**} beginnt, dann folgen beliebige Zeichen und mit \enquote{*/} endet. Der Bezeichner eines Tokens muss mit einem Großbuchstaben beginnen  \cite[S.~3]{ANTLR:APredicated-<i>LLk</i>ParserGenerator}. 

Der nächste Schritt ist das  Parsen. Dabei werden die im vorherigen Schritt generierten Tokens, die als Liste vorliegen, genommen und in eine hierarchische Baumstruktur umgewandelt, wobei hier der Kontext die entscheidende Rolle spielt. ANTLR4 lädt ein Token nach dem anderen und prüft, ob es -- basierend auf der aktuellen Position in der Baumstruktur -- eine Regel gibt, die durch dieses Token erfüllt wird. Wenn es mehrere mögliche Pfade gibt, lädt ANTLR4 so viele Tokens, bis die nächste Regel eindeutig feststeht. Gibt es dennoch Uneindeutigkeiten, so wird die Regel genommen, die als Erstes in der Parser-Datei steht \cite[S.~10ff.]{TheDefinitiveANTLR4Reference}.

So kann eine vereinfachte Parser-Grammatik für Java einen Baumknoten definieren, der eine generelle Methode beschreibt. Eine Methode besteht aus Rückgabetyp, Bezeichner und Parameterliste. Die Parameterliste kann dann als eine Liste von Datentyp-Bezeichner-Paare aufgelöst werden. Der Rückgabetyp einer Methode ist allerdings anders zu verstehen als der Datentyp eines Parameters, da jeder Datentyp eines Parameters auch ein gültiger Rückgabetyp ist, was jedoch nicht umgekehrt der Fall ist. So ist \textit{void} ein gültiger Rückgabetyp, aber kein Datentyp. Listing \ref{lst:parser_example} zeigt einen typischen Ausschnitt aus der Parser-Grammatik von Java \cite{ANTLRgrammarforjava}, wobei zur Übersichtlichkeit nicht alle Regeln und Tokens aufgelistet sind.
		\begin{figure} [htbp]
			\lstinputlisting
			[caption={Beispielhafte Syntax vom Parser},
			label={lst:parser_example},
			captionpos=b, basicstyle=\footnotesize, tabsize=2, showstringspaces=false,  numbers=left,language=ANTLR]
			{figures/chapter4/parser_example.g4}
		\end{figure}
		
Listing \ref{lst:parser_example} beschreibt die notwendigen Regeln, um Methodenparameter zu parsen. Ein Methodenparameter (Z. 1) kann keinen, einen oder mehrere  Modifizierer (Z. 2) enthalten, die ihrerseits eine Java-Annotation oder das Schlüsselwort \textit{final}  sein können (Z. 6--7). Anschließend (Zeile 3) muss ein Datentyp (Z. 9) erfolgen, der wiederum aus einer Annotation bestehen kann (Z. 10), gefolgt von entweder einem primitiven Datentyp oder einem Klassen- bzw. Schnittstellentyp (Z.11). Auch die üblichen eckigen Klammern für Arrays in Java können nach diesem Datentyp folgen (Z. 12). Die letzte Voraussetzung für einen gültigen Methodenparameter ist ein valider Bezeichner (Z. 4), der in Zeile 14--16 genauer definiert wird. 

Die Parser-Grammatik ist ähnlich wie die der Lexer-Grammatik aufgebaut. Auch hier wird eine Variante der regulären Ausdrücke verwendet, wobei hier die reguläre Grammatik auf die Tokens angewendet wird. Anstelle des Namens des Tokens kann alternativ auch die Zeichenkette des Tokens verwendet werden (bspw. \enquote{+} statt \enquote{ADD}). Im Gegensatz zum Lexer muss der Bezeichner einer Parser-Regel mit einem Kleinbuchstaben beginnen \cite[S.~3]{ANTLR:APredicated-<i>LLk</i>ParserGenerator}. So ist eine Unterscheidung zwischen Tokens und den Parserregeln stets möglich. 


\section{GitHub Actions}\label{chapter:github_actions}

GitHub Actions \cite{GithubActions} ist eine von GitHub angebotene Plattform zur Vereinfachung des \ac{CI/CD}'s. Mithilfe von  GitHub Actions wird Programmcode ausgeführt, wenn ein bestimmtes Ereignis stattfindet. Dieses Ereignis kann z.~B. ein Push-Ereignis sein, bei dem neuer Quellcode in das GitHub-Repository hochgeladen wird oder eine neue Version des Programms zum Release freigegeben wird. Der Programmcode kann wahlweise auf einem von  GitHub vorbereiteten System ausgeführt oder auf einem eigenen System ausgeführt werden. Dieses System wird auch als \textbf{Runner} bezeichnet.

Der gesamte Programmcode wird im Kontext von GitHub Actions auch als \textbf{Workflow (Ablauf)} bezeichnet und führt einen oder mehrere \textbf{Jobs} aus. Diese Jobs sind eine Ansammlung von \textbf{Steps (Schritte)}, die man als Befehle interpretieren kann. Die Jobs werden standardmäßig parallel ausgeführt, da keine Abhängigkeit zwischen den Jobs vermutet wird. Ein Step kann ein Befehl sein, der auf einer Kommandozeile ausgeführt werden kann, oder ein Verweis auf eine andere GitHub Action, die dann ausgeführt wird. \cite[S.~5--7]{github_action_book} 

\begin{figure}[htpb!]
\fontsize{7}{10}\selectfont
    \centering
\includesvg[scale=0.75]{figures/chapter2/workflow_schema.svg}
    \caption{Schema: Workflows}
    \label{fig:workflow_schema}
\end{figure}

Abbildung \ref{fig:workflow_schema} zeigt schematisch, wie ein Workflow in einem GitHub-Projekt ausgeführt werden kann. Ein Benutzer löst beispielsweise durch einen Push ein Ereignis aus. Daraufhin werden für jeden Job ein Runner initialisiert, die aus dem Repository das Projekt klonen, um so mit einer geklonten Kopie zu arbeiten.  Das Klonen des Repositorys ist dabei nicht obligatorisch, ist aber notwendig, falls mit dem Quelltext des Projektes gearbeitet werden soll.  Anschließend werden die Jobs gestartet, die ihrerseits wieder die Steps ausführen. Jeder Job wird auf einem separaten Runner ausgeführt und läuft parallel, außer der Benutzer gibt explizit eine Abhängigkeit zwischen den Jobs an. 


Schlägt der Programmcode fehl, kann der Nutzer den Grund des Fehlers über die  \enquote{Actions}-Registerkarte herausfinden. Dort kann der Nutzer auch sämtliche Ausgaben des Programms ansehen, die auf der Konsole ausgegeben werden.

\subsubsection{Verwendungsmöglichkeiten für GitHub Actions}

Ein Anwendungsfall von GitHub Actions sind automatisierte Tests. Bei einem Push-Ereignis kann der aktuelle Programmcode mit einer geeigneten Testbibliothek getestet werden, sodass im Falle eines fehlgeschlagenen Tests der Programmierer informiert wird und die notwendigen Änderungen veranlassen kann.
Des Weiteren kann das Deployment (z.~dt. Verteilung) der Software mittels einer Action automatisiert erfolgen. So lässt sich z.~B. bei Programmen, die auf verschieden Plattformen (NPM, Yarn, NuGet etc.)  veröffentlicht werden, sicherstellen, dass stets die aktuelle Version auf jeder Plattform verfügbar ist. So können Aktualisierungen schnell verteilt werden, was auch zu einer höheren Softwarequalität und einem besseren Schutz vor Sicherheitslücken führen kann. 
Auch die Qualität des Codes kann mit geeigneten Actions geprüft werden, was im Kontext dieser Bachelorarbeit besonders interessant ist. \cite[S.~1ff.]{github_action_book}



\subsubsection{Erstellung eines Workflows}
Ein Workflow kann über die Registerkarte \enquote{Actions} erstellt werden und wird intern in dem Verzeichnis \enquote{.github/workflows} gespeichert. Abbildung \ref{lst:simple_workflow} illustriert eine typische Workflow-Datei, die standardmäßig erstellt wird.


\begin{figure}[ht!]
	\lstinputlisting
			[caption={Beispielhafte Workflow-Datei},
			label={lst:simple_workflow},
			captionpos=b,language=YAML, basicstyle=\footnotesize, tabsize=1, showstringspaces=false,  numbers=left]
			{figures/chapter2/workflow_example.yaml}
			\end{figure}
In Zeile 1 wird der Name des Workflows festgelegt. Anschließend werden die Bedingungen festgelegt, die den Workflow starten. In diesem Beispiel wird dieser Workflow bei einem Push (Z. 3) oder ein Pull-Request (Z. 5) ausgeführt, wenn dabei die Main-Branch betroffen ist. Mit \enquote{workflow\_dispatch} wird zusätzlich ermöglicht, den Workflow auch manuell zu starten, was zu Debugging-Zwecken sinnvoll sein kann. In Zeile 8 werden dann die Jobs definiert, wobei hier nur ein Job namens \enquote{build} (Z. 9) erstellt wird. Der Job benötigt einen Runner, der hier ein System mit einer aktuellen Ubuntu-Version ist (Z. 10). Als Nächstes werden die einzelnen Schritte deklariert. Jeder Schritt beginnt mit einem Bindestrich. Der erste Schritt (Z. 12) sorgt dafür, dass der Quellcode der entsprechenden Branch des Repositorys auf das System geklont wird. Dabei wird auch eine Umgebungsvariable namens \enquote{\$GITHUB\_WORKSPACE} bereitgestellt, die den Pfad des geklonten Repositorys enthält. Der nächste Schritt (Z. 13--14) gibt den Text \enquote{Hello, world!} auf der Kommandozeile aus. Der letzte Schritt (Z. 17--19) zeigt exemplarisch, dass auch mehrere Kommandozeilenbefehle sequenziell ausgeführt  werden können.

\subsubsection{Ausführung von Workflows}
Sobald ein Workflow durch ein Ereignis ausgeführt wird, kann ein Benutzer den Programmablauf live über die Registerkarte \enquote{Actions} einsehen. Nachdem der Workflow abgeschlossen wurde, können hier auch Informationen über den Erfolg bzw. Misserfolg abgerufen werden. Beispielsweise können die Ausgaben auf der Konsole angesehen werden, die bis zu 90 Tage gespeichert werden \cite[S.~53]{github_action_book}.  Des Weiteren kann ein Benutzer auch erfahren, wie viel Zeit der Workflow benötigt hat, wobei hier auch der Zeitbedarf der einzelnen Schritte angezeigt wird. 

\begin{figure}[ht!]
    \centering
    \includegraphics[width=0.9\columnwidth]{figures/chapter2/workflow_output.png}
    \caption{Ausgabe eines Workflows}
    \label{fig:workflow_output}
\end{figure}

Abbildung \ref{fig:workflow_output} zeigt, wie ein Benutzer den Ablauf eines Workflows einsehen kann. Der Nutzer kann durch einklappbare Gruppen die Ausgaben der einzelnen Schritte einsehen, sodass die Schritte für die Initialisierung etc. nicht die Übersicht stören. Zudem befindet sich auf der rechten Seite der Zeitbedarf eines Schrittes. Durch das rote Kreuz erfährt ein Nutzer, dass dieser Schritt fehlgeschlagen ist. 


\subsubsection{Erstellung einer eigenen Action}
Um eine eigene GitHub Action zu erstellen, muss in dem Hauptverzeichnis des Repositorys, in dem der Programmcode der Action liegt, eine Datei namens \enquote{action.yaml} oder \enquote{action.yml} erstellt werden. Listing \ref{lst:create_action_example} zeigt eine beispielhafte \enquote{action.yaml}.
	\begin{figure}[h!]
			\lstinputlisting
			[caption={Beispielhafte Action-Konfigurationsdatei},
			label={lst:create_action_example},
			captionpos=b, basicstyle=\footnotesize, tabsize=1, showstringspaces=false,  numbers=left,language=YAML]
			{figures/chapter2/create_action_example.yaml}
		\end{figure}
Zunächst wird der Name der Action und eine Beschreibung definiert (Z.~1--2). Anschließend können Eingabeparameter definiert werden, die später im Programm verwendet werden können (Z.~3--7). Zu jedem Parameter muss auch festgelegt werden, ob er zwingend erforderlich ist. Außerdem kann der Standardwert des Parameters definiert werden. Zusätzlich können Ausgabeparameter festgelegt werden, die spätere Actions als Eingabe nutzen können (Z.~8--10). Danach (Z.~11--13) wird festgelegt, wie diese Action ausgeführt wird. Eine Action kann in einer JavaScript-Umgebung, in einem Docker-Container oder als Liste von verschiedenen Schritten ausgeführt werden \cite[S.~117ff.]{github_action_book}. 

\subsubsection{Verhindern von Merge}

Eine fehlgeschlagene GitHub Action kann verwendet werden, um einen einen Merge zu verhindern. Dies geschieht allerdings nicht automatisch, sondern muss explizit aktiviert werden. Dazu muss in den Einstellungen des Repositorys, bei dem durch eine fehlgeschlagene Aktion ein Merge verhindert werden soll, eine \enquote{Branch protection rule (z.~dt. Zweigschutzregel)} aktiviert werden. In dieser Regel kann festgelegt werden, dass ein Merge abgelehnt wird, wenn ein bestimmter Job eines Workflows nicht erfolgreich war. Ein Merge kann trotz des Fehlschlages durch einen Administrator erzwungen werden. 
\section{Verwandte Werkzeuge}\label{chapter:related_tools}
Um die Qualität der Softwaredokumentation in Javadoc zu bewerten, gibt es bereits einige Programme. In vielen Fällen handelt es sich dabei um Programme, die nicht nur auf die Bewertung der Softwaredokumentation beschränkt sind, sondern auch andere Fälle von unsauberem Code erkennen können. Da die Bewertung der Dokumentation nicht der primäre Zweck der Programme ist, sind die verwendeten Algorithmen recht allgemein und erkennen viele Problemfälle nicht. Gleichwohl sind diese Programme dadurch, dass sie viele \enquote{Code-Smells} erkennen, geeignet, um sich ein Bild über die Qualität des Quellcodes zu verschaffen und den Entwickler zu Clean-Code zu motivieren. 
\subsubsection{Checkstyle}
\newcommand{\cs}{\textit{Checkstyle }}
Ein bekanntes Programm ist \cs \cite{Checkstyle}. \cs ist ein Open-Source-Programm, das Verstöße gegen bestimmte Fehlern in Java-Quellcode erkennt und Warnungen dazu anzeigt.   Mit \cs lässt sich beispielsweise prüfen, ob alle Methoden überhaupt einen Javadoc-Block besitzen, der Javadoc-Block korrekt platziert ist oder ein Javadoc-Tag wie zum Beispiel \enquote{@param} auch mit einer zusätzlichen Begründung versehen ist. Außerdem kann  \cs überprüfen, ob \ac{HTML}-Tags korrekt geschlossen sind und jede Zeile im Javadoc-Block mit einem Asterisk beginnt.


Für jeden Verstoß gibt \cs  eine Zeile aus, welche dem Anwender bei der Behebung des Problems helfen soll. Listing \ref{lst:checkstyle_out} zeigt eine typische Zeile, die Checkstyle ausgibt, wobei zur Übersichtlichkeit diese einzelne Zeile auf mehrere Zeilen verteilt wurde:

	\begin{figure}[h!]
			\lstinputlisting
			[caption={Beispielhafte Ausgabe von Checkstyle},
			label={lst:checkstyle_out},
			captionpos=b, basicstyle=\footnotesize, tabsize=1, showstringspaces=false,  numbers=left,language=xml]
			{figures/chapter2/checkstyle_out.txt}
		\end{figure}
		
Diese Zeile enthält die Schwere des Verstoßes (Z. 1), den absoluten Pfad der betroffenen Datei (Z. 2), welcher hier aufgrund der Länge gekürzt ist, die Zeilen- und Spaltennummer (Z. 3), in der das Problem auftritt, eine Beschreibung des Fehlers (Z. 4) und einen Fehlercode (Z. 5). Die Schwere eines Verstoßes kann für jeden Fehler konfiguriert werden. Eine vollständige Auflistung der Fehler, die \cs bezüglich der Dokumentation finden kann,  existiert in \cite{checkstyle_doc_metrics}.

			
\cs lässt sich mit einer Extensible-Markup-Language-Datei konfigurieren, die festlegt, welche Regeln von \cs überprüft werden sollen. Dabei kann beispielsweise festgelegt werden, ob Kommentare bei privaten Komponenten nicht zwingend notwendig sind oder kurze Methoden nicht dokumentiert sein müssen.
\cs lässt sich zudem in \ac{IDE}s wie \textit{Eclipse} einbinden, um den Entwickler leicht auf Fehler hinzuweisen. 
\subsubsection{PMD}
Des Weiteren gibt es das Programm PMD \cite{PMD}, das ebenfalls Fehler in Softwaredokumentationen finden kann.  Anders als Checkstyle unterstützt PMD auch andere Sprachen als Java, sodass beispielsweise einige Fehler in JavaScript gefunden werden können. Dazu gehören aber keine Fehler bezüglich der Dokumentation.

Im Bereich  Javadoc erkennt \textit{PMD} wie \cs nicht dokumentierte Komponenten. Zudem kann \textit{PMD} bestimmte Wörter erkennen, die als anstößig oder schwieriger verständlich empfunden werden. Auch eine maximale Länge eines Kommentars in puncto maximale Anzahl an Zeichen pro Zeile und maximale Anzahl an Zeilen pro Kommentar kann festgelegt werden. Allerdings sollte beachtet werden, dass diese Regeln für alle Kommentare (einschließlich einzeilige und normale mehrzeilige) gelten und damit nicht auf Javadoc beschränkt sind. 

Ähnlich wie \cs gibt \textit{PMD} gefundene Verstöße auf der Konsole aus. Die Struktur dieser Ausgabe ähnelt sehr der von \textit{Checkstyle}, da sie ebenfalls den vollständigen Pfad, die Zeilennummer und einen Fehlercode mit einer Beschreibung enthält. Nur die Spaltennummer  und einen Hinweis auf den Schweregrad des Verstoßes existiert nicht. Ähnlich wie \cs kann \textit{PMD} mittels einer Extensible-Markup-Language-Datei konfiguriert werden.

\subsubsection{Javadoc}
Das oben erwähnte Javadoc-Tool bietet ebenfalls die Möglichkeit, beim Generieren der HTML-Datei die Qualität des Javadocs zu prüfen. Dabei werden vor allem fehlende Tags für Parameter etc. bemängelt. Zudem erkennt Javadoc auch Tabellen mit fehlender Überschrift und andere Designmängel, die in der \ac{HTML}-Seite später auffallen. Auch fehlerhaftes \ac{HTML} kann erkannt werden.

\section{Verwandte Arbeiten}\label{chapter:related_science}

Neben den praktischen Tools, die den Softwareentwickler bei der Bewertung der Softwaredokumentation unterstützen, wurden auch einige wissenschaftliche Arbeiten veröffentlicht, die sich mit Metriken über Softwaredokumentation auseinandersetzen. In diesen Arbeiten werden auch Programme vorgestellt, welche diese Metriken nutzen, allerdings sind die Quelltexte bzw.  lauffähige Versionen der Programme ohne Weiteres nicht verfügbar, sodass ein Vergleich mit dem zu entwickelnden Tool nicht möglich ist. 

Einige wissenschaftliche Arbeiten haben im weiteren Verlauf der Bachelorarbeit keine Relevanz und werden daher nur der Vollständigkeit halber erwähnt. Beispielsweise ermöglicht das Programm \textit{iComment}, welches in  \cite[S.~145ff.]{icomment} beschrieben wird, Inkonsistenzen zwischen Dokumentationen und Quellcode in C-Programmen zu finden. Die Autoren verwenden hierfür komplexere \ac{NLP}-Techniken und führen eine statische Quellcodeanalyse durch. Da diese Themenblöcke den Rahmen dieser Bachelorarbeit sprengen würden, werden sie nicht weiter verfolgt.


\subsubsection{Quasoledo}\label{chapter:Quasoledo}
In \cite[S.~4--10]{HowDocumentationEvolvesoverTime} geben die Autoren einige Metriken an, die sie für die Bewertung der Softwaredokumentation als nützlich erachten, und stellen ein Programm namens \textit{}{Quasoledo} vor, das mittels dieser Metriken Softwaredokumentationen analysieren kann. Zu den Metriken gehören z.~B.  \textit{ANYJ},  welches den Anteil der dokumentierten Deklarationen an allen Deklarationen beschreibt und \textit{Flesch-Kindcaid}, welches die Lesbarkeit von Texten beschreibt.

Die Arbeit wertet anschließend die Javadoc-Dokumentation von Eclipse aus und findet heraus, dass öffentliche Methoden häufiger dokumentiert sind und ihre Dokumentation oft lesbarer ist. Außerdem wenden die Autoren das Tool auf die gesamte Versionshistorie von Eclipse bis zum 8. April 2006 an und plotten den Verlauf der Dokumentationsqualität über diesem Zeitraum. Dabei wird sichtbar, dass die Qualität am Anfang des Projektes noch sehr stark schwankt, aber nach einiger Zeit recht konstant bleibt. 
\subsubsection{JavaDocMiner}
Eine weitere Arbeit, die eine der Grundlagen dieser Bachelorarbeit ist, ist der \textit{JavaDocMiner} \cite[S.~68--79]{AutomaticQualityAssessmentofSourceCodeComments:TheJavadocMiner}. In diesem Konferenzpapier wird ein Programm beschrieben, welches mittels einfacher Heuristiken eine Einschätzung der Softwaredokumentation ermitteln kann.

Insgesamt verwendeten die Autoren viele Metriken aus dem Tool \hyperref[chapter:Quasoledo]{Quasoledo}, führen aber auch neue Metriken ein. Dazu gehört eine Metrik, welche die Anzahl der Abkürzungen zählt, da diese laut den Autoren vermieden werden sollten. Auch die durchschnittliche Anzahl an Wörtern pro Javadoc-Kommentar wird als Metrik verwendet. 

Anschließend wenden die Autoren das Tool auf den Quellcode von \textit{ArgoUML} und \textit{Eclipse} an und prüfen, ob es eine Korrelation zwischen der Anzahl an Bugs und der Qualität der Dokumentation nach den benannten Metriken gibt. Die Autoren finden dabei heraus, dass die \textit{Kincaid}-Metrik nur wenig mit der Anzahl der Bugs korreliert, während es bei anderen Metriken wie z.~B. \textit{ANYJ} eine starke negative Korrelation gibt. 

\begin{comment}
\subsubsection{Doc2Spec}
Die Autoren in \cite[S.~307ff.]{InferringResourceSpecificationsfromNaturalLanguageAPIDocumentation} stellen ein Tool namens \textit{Doc2Spec} vor und erläutern ein Verfahren, um herauszufinden, ob eine API korrekt verwendet wurde. Dabei werden die Javadoc-Kommentare einer API analysiert und dann mit der Verwendung der API verglichen, um Fehler bei der Handhabung der API zu finden. 

Für jede dokumentierte Methode der API wird ein Aktion-Ressource-Paar erstellt. Diese beschreibt, welche Aktion auf welche Ressource ausgeführt wird. Bei einer Methode namens \textit{close}, die mit dem englischen Text \enquote{Initiates close of the connection handle at the
application level} dokumentiert wird, lässt sich beispielsweise schlussfolgern, dass das Aktion-Ressource-Paar \textit{(close,connection)} sein kann; denn die Aktion \textit{close} bezieht sich auf die Ressource \textit{connection}. Dabei sind aber manchmal mehrere Aktion-Ressource-Paare möglich \cite[S.~308]{InferringResourceSpecificationsfromNaturalLanguageAPIDocumentation}.

Anschließend werden die gefundenen Ressourcen anhand der Klassenhierarchie passend gruppiert. Außerdem werden die Aktionen in fünf Kategorien eingeordnet, in der die meisten Java-Methoden passen. Die Kategorien sind Methoden, die eine Ressource oder Objekt erstellen, eine Ressource sperren, auf eine Ressource zugreifen, eine gesperrte Ressource wieder freigeben und Ressourcen schließen. 

Mit diesen generierten Informationen kann dann bei Quelltext, welches diese API verwendet, geprüft werden, ob die Methoden dieser Ressource in der richtigen Reihenfolge aufgerufen werden. Beispielsweise muss eine Ressource zuerst erzeugt und gesperrt werden, bevor irgendwelche Manipulationen angewendet werden. Außerdem kann geprüft werden, ob eine Ressource auch wieder freigegeben und geschlossen wird, sodass Speicherlecks verhindert werden. Dabei werden alle möglichen Ausführungspfade einer Methode geprüft, da ein fehlendes Freigeben von Ressourcen z.~B. im Ausnahmefall ein häufiger Fehler sein kann. 

\end{comment}
\subsubsection{Javadoc-Fehler in Open-Source-Software}
In \cite[S.~249ff.]{JavadocViolationsandTheirEvolutioninOpen-SourceSoftware} analysieren die Autoren 163 Open-Source-Projekte aus GitHub, die in Java geschrieben sind, und prüfen, wie oft Komponenten nicht mit Javadoc kommentiert sind oder die Dokumentation unvollständig ist. Dabei werden private Komponenten, Getter und Setter von der Analyse ausgeschlossen, da sie laut den Autoren nicht zwangsläufig dokumentiert sein müssen. 

Das Ergebnis der Studie lautet, dass Methoden besonders oft Javadoc-Fehler aufweisen. Wird dies allerdings in Relation zur Häufigkeit der jeweiligen Komponente gesetzt, so haben Konstruktoren eine hohe Wahrscheinlichkeit, fehlerhaftes Javadoc zu besitzen. Dies könnte laut den Autoren daran liegen, dass Konstruktoren als selbsterklärend wahrgenommen werden. Außerdem ist der Grund für Javadoc-Fehler in den meisten Fällen, dass eine Komponente komplett undokumentiert ist. Auch undokumentierte \enquote{@throws}-Tags, welche die möglichen Ausnahmen einer Methode beschreiben, sind sehr häufig. Deutlich seltener als undokumentierte Ausnahmen sind undokumentierte Parameter und Rückgabewerte. Zudem stellt die Studie fest, dass solche Javadoc-Fehler im Mittel über zwei Jahre nicht behoben werden, sodass die Softwaredokumentation oft unvollständig ist. 

\begin{comment}
\subsubsection{iComment}
Das Programm \textit{iComment}  wurde hauptsächlich für C-Programme entwickelt, um Probleme zwischen der Dokumentation und dem Quellcode zu finden. Dabei konzentriert sich das Programm auf das Finden von Synchronisationsproblemen, die bei Programmen mit mehreren Threads auftauchen können.  Bei einem exklusiven Ausschluss besitzt eine Methode einen sogenannten Lock auf ein Objekt und nur diese Methode darf mit dem Objekt arbeiten.

Setzt nun die Dokumentation einen Lock voraus, aber der Programmierer hat keinen Lock angefordert, können sehr schnelle und subtile Bugs entstehen, die nur schwer findbar sind. \cite[S.~145ff.]{icomment}

Das Programm wurde auf dem Quellcode des Linux-Kernels und Mozilla angewandt und dabei mögliche Bugs gefunden, die später auch von den Entwicklern bestätigt wurden\cite[S.~146.]{icomment}.
\end{comment}

\subsubsection{@tComment}\label{@tComment}
Ein anderer Ansatz, der ebenfalls mit Javadoc arbeitet, wird \textit{@tComment} genannt \cite[S.~1ff.]{@tComment:TestingJavadocCommentstoDetectComment-CodeInconsistencies}. Dabei wurde die Konsistenz der Javadoc-Dokumentation mit dem tatsächlichen Programmcode verglichen. Anders als bei den  vorherigen Ansätzen wird hier das Programm dynamisch ausgeführt. Dabei werden die verschiedenen Methoden und ihr dazugehörige Javadoc-Dokumentation analysiert und daraus mittels einfacher Heuristiken ermittelt, ob ein  Nullwert für einen Parameter eine Inkonsistenz zwischen Dokumentation und Quellcode offenbart.

Beispielsweise kann die Dokumentation einer Java-Methode beschreiben, dass ein Parameter nicht \textit{null} sein darf. Daraus kann gefolgert werden, dass ein Nullwert für diesen Parameter zu einer Ausnahme führt. Wenn diese Ausnahme dann auch in der Dokumentation genauer spezifiziert ist, sollte genau diese Ausnahme bei einem Nullwert geworfen werden. 
Falls Nullwerte explizit erlaubt sind, sollte die Methode sich dann stets korrekt verhalten und keine Ausnahmen werfen. 

\textit{@tComment} kann mit diesen einfachen Regeln jede Methode ausführen und prüfen, ob sich die Methode tatsächlich verhält, wie die Dokumentation es beschreibt. Dabei verwendet das Programm einfache  semantische Heuristiken in der englischen Sprache. Zum Beispiel prüft das Programm, ob die kurz vor dem Wort \enquote{null} ein negierendes Wort wie \enquote{not} oder \enquote{never} auftaucht und klassifiziert dann den dazugehörigen Parameter als Parameter, der nie \textit{null} sein darf. 
