\subsection{Context}\label{sec:context}
In section \ref{sec:pipeline_steps}, the several steps of the data clump pipeline are outlined. However, these steps do not include how the information generated by each step is stored and how successive steps might use this information.

Therefore, a concept to store intermediate information needs to be developed. Such information might be called \textbf{context}.

The context is a repository filled throughout the data clump refactoring pipeline. For instance, it might be stored in memory or a database if the context size is too large.The context can be represented as a linked list. Each node of the list represents a part of the context.
Each context is an extension of a previous context. In the beginning, there is no context and the code obtaining context is created. If a handler needs to access information from a specific context, it needs to traverse the linked list until it finds the needed information. 


Each step in the data clump refactoring pipeline can access the context and obtain such information as it may deem necessary for its use. A step may or may not update the context. For instance, if a service performs multiple step consecutively, it might not be able to store some information. To give a more concrete example, if a service can find data clumps and refactor them automatically, it might not be able to store the locations of each data clump so that respective context cannot be created. Also, a step can create multiple chained contexts if a step is capable of executing multiple steps. 

\begin{figure}
   \includesvg{figures/chapter3/context_pipeline_drawio.svg}
\caption{Exemplary lifecycles of the context: a) All steps are performed by an \ac{LLM}, b) Detection and filtering by another tool, c) Only name suggestion by \ac{LLM}}
\label{fig:context_lifecycle}
\end{figure}

Figure \ref{fig:context_lifecycle} illustrates how a different combination of handlers can affect the state of the context. The figure depicts a state diagram where rectangles visualize the most recent context and arrows indicate executed steps.  In the left part (a), the \ac{LLM} performs the detection of data clumps, and the refactoring (including all associated sub-tasks). Because all these task are performed by the same service, it would be unnecessary to save intermediate results. Therefore, the context is only updated once at the conclusion of the program. This final context does not have additional information but marks that the pipeline has been executed successfully.
 


In part b in the center of the figure, some parts of the pipeline are performed by the \textit{DataClumpDoctor} and other programs. For instance, data clumps are detected by the \textit{DataClumpDoctor} . As a result, a data clump detector context is created containing all detected data clumps. Afterwards, a filter removes non-important data clump and creates a new context of the same type that is linked to the previous context. If a later handler requires information about the detected data clump, it needs to find the first context that contains this information  beginning at the tail of the linked list. In this case it would be the filtered data clump context not the original data clump context. Here, also the context is not updated until the final step because the refactoring is performed via an \ac{LLM}. 

On the right side of the figure, the context is extended by a name finding context. This context includes information about a suitable identifier suggested by a \ac{LLM}. A manual refactoring tool (e.~g. IntelliJ), can use this context to perform the refactoring without further input by an \ac{LLM} so that the role of the model is limited here. 




To check whether a given pipeline is indeed executable, each step handler must describe how the context is updated when the step is executed. Each step can also specify whether a specific type of context must exist. For instance, a step may require that the \ac{AST} is available for a given source code file. 

Such context can only work if the context data is in a specific format, which can be generated by one step and might be correctly interpreted by each successive step. 