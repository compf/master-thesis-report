To conclude this master thesis, a modular approach for detecting and refactoring data clumps can have many advantages.  For instance, an extension to other programming languages, operating systems or build plattforms is easier so that the usability of such a tool is increased. Nevertheless, performance issues and configuration issues are some arguments against the modular method. 

In this master thesis, only data clumps are considered and refactored. However, some developers might regard data clumps not as a serious code smell. Hence, extending the general design of the tool to other code smells would be an interesting research task as more code smells can be found and refactored without loosing the modular design. This requires for instance, that the \enquote{data clump detection} step needs to be more general (e.g. \enquote{code smell detection step}. Also, the \enquote{name finding} step might be removed or replaced with another suitable step. 

As this master thesis, show ChatGPT can be very helpful in some steps of the data clump detection process. However, it is not suitable for performing the whole process alone for large projects since the context size, the inherent randomness, and the costs are major limitations which cannot be ignored. Nevertheless, \ac{LLM} like ChatGPT can be a great help for developers to find and refactor code smells and their appropriate usage will be an important research topic. 

In general,the topic \ac{LLM} is a very popular target of research with new updates and improvements being published frequently. This means that many problems considered in this master thesis might have already been addressed or are not as relevant as they were a short time ago. Research in large language model is hence constantly evolving and promises many more innovations. Nevertheless, the main concerns cannot be ignored and will still be relevant.

While \acp{LLM} have been existing for some time, only the fairly recent release of ChatGPT have enabled developers around the world to use the advantages of such models in their daily developments. As a result, the impact of tools like ChatGPT on software development are part of current scientific research. This includes the need to deal with the challenges and limitations of ChatGPT while employing the undeniable potentials and powers of ChatGPT in the software development of the future. 
\begin{comment}
Ziel dieser Bachelorarbeit war es, ein Tool zu Bewertung der Dokumentation zu entwickeln, das in einem \ac{CI/CD}-Prozess eingebunden werden kann und nicht auf einer Programmiersprache beschränkt ist. Dabei beschränkt sich diese Bachelorarbeit auf strukturierte Kommentaren wie z.~B. Javadoc. Dieses Ziel wurde im Großen und Ganzen erreicht.

Durch die allgemein gehaltene Klassenstruktur für das Parsing ist es möglich, Quellcode in anderen Programmiersprachen bewerten zu lassen. Allerdings muss dafür ein entsprechender Parser geschrieben werden, welcher den Quellcode in die vorgegebene Struktur transformiert. Dabei ist es natürlich nicht möglich, jedes Detail abzubilden, sondern es müssen Abstriche gemacht werden. Nichtsdestotrotz können auch sprachspezifische Eigenheiten berücksichtigt werden, indem eine entsprechende abgeleitete Klasse von \textit{ComponentMetaInformation} gebildet wird und diese sprachspezifischen Informationen dort gespeichert werden. Diese Daten können von einem geeigneten \textit{LanguageSpecificHelper} dazu verwendet werden, um sprachabhängige Details bei der Bewertung der Dokumentation zu berücksichtigen. 

Auch das Parsen der strukturierten Kommentare erfolgt recht abstrakt, indem  die Informationen in den Beschreibungstexten unstrukturiert als Zeichenketten gespeichert werden, sodass die einzelnen Metriken diese Informationen weiterverarbeiten müssen. Da es Metriken gibt, die mit den einzelnen Wörtern ein eines Kommentars arbeiten und auch Metriken, welche die interne Struktur des Kommentars analysieren, wäre es ein mögliches Forschungsthema, wie diese zwei Darstellungen besser repräsentiert werden können. 

Um das Tool konfigurierbar zu halten, wurde ein Konzept für eine Konfigurationsdatei im \ac{JSON}-Format vorgestellt, das alle wichtigen Informationen enthält. Die Konfiguration kann auch über GitHub Actions durchgeführt werden, indem passende Umgebungsvariablen gesetzt werden.  So kann das Tool sowohl als reguläres Programm auf einem lokalen System verwendet werden als auch mittels GitHub Actions in den \ac{CI/CD}-Prozess eingebunden werden. Durch die flexible Konfiguration kann ein Nutzer frei entscheiden, welche Metriken er für sinnvoll hält und wie er sie gewichten will. Dabei überschreibt die Konfiguration mittels GitHub Actions stets die Konfiguration in der \ac{JSON}-Datei. Außerdem können die Metriken selbst begrenzt konfiguriert werden. Eine Nutzung des Tools auf anderen \ac{CI/CD}-Plattformen, die mit GitHub Actions vergleichbar sind,  ist prinzipiell ebenfalls möglich, da die Konfiguration von dem  übrigen Programm entkoppelt ist.

Für das Tool wurden bereits einige Metriken entwickelt, welche verschiedene Bereiche der Dokumentation analysieren können. Leider war eine Evaluation der einzelnen Metriken nicht möglich, sodass weiterhin offenbleibt, welche Metriken in welchen Situationen valide Ergebnisse liefern und wie eine sinnvolle Gewichtung der Metriken aussehen kann.  Weitere Metriken lassen sich durch Einfügen einer neuen abgeleiteten Klasse von \textit{DocumentationAnalysisMetric} bilden. Schwierig kann im konkreten Einzelfall allerdings das Finden einer geeigneten Funktion werden, welche die Werte der Metrik in das vorgegebene Intervall von 0 bis 100 transformiert. Mögliche Ideen für weitere Metriken lassen sich in \cite{checkstyle_doc_metrics} finden. Auch die wissenschaftliche Literatur liefert weitere Metriken, die fortschrittliche Techniken im Bereich des \ac{NLP} nutzen und daher im Rahmen dieser Bachelorarbeit zu komplex waren. Beispielhaft sei hier das Tool \enquote{iComment} aus  \cite[S.~145ff.]{icomment} genannt, bei dem geprüft wurde, ob die Dokumentation mit dem Code auch konsistent ist und somit korrekt und aktuell ist. Diese Metriken können als Inspiration genommen werden, um die Dokumentationsqualität umfassender analysieren zu können, sodass Entwickler bei der Identifikation und Behebung von mangelhafter Softwaredokumentation  besser unterstützt werden.


\end{comment}