This chapter covers the evaluation of the master thesis. The goal of the evaluation is to assess the suitability of ChatGPT in performing  different steps of the refactoring pipeline, and whether such refactoring is accepted. The evaluation is split into two distinct experiments that use different methodologies. 
In section \ref{sec:pull_request_eval} the  first experiment is discussed. Here, pull requests to several GitHub projects were submitted. In each PR  a specific data clump was selected and refactored, and feedback regarding that pull request was collected.

Afterwards, section \ref{sec:metric_based_eval} outlines  the second experiment, a smaller set of GitHub projects was selected and analyzed by the tool to determine the detection, filtering, and refactoring capabilities of ChatGPT using metrics.
This two-sided evaluation approach integrates both human feedback and systematic analysis to provide a comprehensive understanding of the tool's efficacy and applicability.  As both experiments have their limitations and challenges, it can be useful to perform these distinct experiments to evaluate the potential of ChatGPT in the data clump refactoring pipeline.








\input{Evaluation/evalPartA}


\input{Evaluation/evalPartB}