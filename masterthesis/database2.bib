% Encoding: UTF-8

@InProceedings{AutomaticQualityAssessmentofSourceCodeComments:TheJavadocMiner,
  author    = {Khamis, Ninus and Witte, Ren{\'e} and Rilling, Juergen},
  title     = {Automatic Quality Assessment of Source Code Comments: The JavadocMiner},
  booktitle = {Natural Language Processing and Information Systems},
  year      = {2010},
  editor    = {Hopfe, Christina J. and Rezgui, Yacine and M{\'e}tais, Elisabeth and Preece, Alun and Li, Haijiang},
  publisher = {Springer Berlin Heidelberg},
  isbn      = {978-3-642-13881-2},
  pages     = {68--79},
  doi       = {10.1007/978-3-642-13881-2_7},
  abstract  = {An important software engineering artefact used by developers and maintainers to assist in software comprehension and maintenance is source code documentation. It provides insights that help software engineers to effectively perform their tasks, and therefore ensuring the quality of the documentation is extremely important. Inline documentation is at the forefront of explaining a programmer's original intentions for a given implementation. Since this documentation is written in natural language, ensuring its quality needs to be performed manually. In this paper, we present an effective and automated approach for assessing the quality of inline documentation using a set of heuristics, targeting both quality of language and consistency between source code and its comments. We apply our tool to the different modules of two open source applications (ArgoUML and Eclipse), and correlate the results returned by the analysis with bug defects reported for the individual modules in order to determine connections between documentation and code quality.},
  address   = {Berlin, Heidelberg},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/2010_Book_NaturalLanguageProcessingAndIn.pdf:PDF},
}

@Article{SoftwareDocumentationManagementIssuesandPractices:ASurvey,
  author   = {C J, Satish and Mahendran, Anand},
  title    = {Software Documentation Management Issues and Practices: A Survey},
  doi      = {10.17485/ijst/2016/v9i20/86869},
  volume   = {9},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/Article50.pdf:PDF},
  journal  = {Indian Journal of Science and Technology},
  month    = {05},
  priority = {prio1},
  year     = {2016},
}

@InProceedings{Qualityanalysisofsourcecodecomments,
  author    = {Steidl, Daniela and Hummel, Benjamin and Juergens, Elmar},
  booktitle = {2013 21st International Conference on Program Comprehension (ICPC)},
  title     = {Quality analysis of source code comments},
  doi       = {10.1109/ICPC.2013.6613836},
  pages     = {83-92},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Quality_analysis_of_source_code_comments.pdf:PDF},
  priority  = {prio1},
  year      = {2013},
}

@WWW{PMD,
  title    = {PMD},
  url      = {https://pmd.github.io/},
  urldate  = {2022-02-17},
  priority = {prio1},
}

@WWW{Checkstyle,
  title    = {Checkstyle},
  url      = {https://checkstyle.sourceforge.io/},
  urldate  = {2021-12-16},
  priority = {prio1},
}

@misc{treude2020accuracy,
      title={Beyond Accuracy: Assessing Software Documentation Quality}, 
      author={Christoph Treude and Justin Middleton and Thushari Atapattu},
      year={2020},
      eprint={2007.10744},
      archivePrefix={arXiv},
      primaryClass={cs.SE}
}

@WWW{ANTLR,
  title    = {ANTLR},
  url      = {https://www.antlr.org/},
  urldate  = {2022-02-17},
  priority = {prio1},
}

@WWW{GithubActions,
  title    = {Github Actions},
  url      = {https://docs.github.com/en/actions},
  urldate  = {2021-12-16},
  priority = {prio1},
}

@WWW{ANTLRgrammarforjava,
  title    = {ANTLR-Grammatik für Java},
  url      = {https://github.com/antlr/grammars-v4/tree/master/java},
  urldate  = {2022-02-17},
  priority = {prio1},
}

@InProceedings{EvaluatingtheQualityoftheDocumentationofOpenSourceSoftware,
  author    = {Lerina Aversano and Daniela Guardabascio and Maria Tortorella},
  title     = {Evaluating the Quality of the Documentation of Open Source Software},
  booktitle = {ENASE},
  year      = {2017},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/f3f43b0c19d7a73db0f78b10bfa2b411f341.pdf:PDF},
}

@Article{Qualitycontrolinsoftwaredocumentationbasedonmeasurementoftextcomprehensionandtextcomprehensibility,
  author   = {Franz Lehner},
  title    = {Quality control in software documentation based on measurement of text comprehension and text comprehensibility},
  journal  = {Information Processing \& Management},
  year     = {1993},
  volume   = {29},
  number   = {5},
  pages    = {551-568},
  issn     = {0306-4573},
  doi      = {https://doi.org/10.1016/0306-4573(93)90079-S},
  url      = {https://www.sciencedirect.com/science/article/pii/030645739390079S},
  abstract = {The importance of software documentation and the effects of poor documentation in data processing are often underrated. Little research has been published that evaluates the quality of software documentation. The evaluation of textual attributes such as comprehensibility, readability, etc., has seen more studies and relatively sound results. Thus this paper exclusively handles textual documentation, whereby the methods are employed for the evaluation of software documentation. We first introduce the methods used in the measurement of text comprehensibility. Then RMS (Readability Measuring System), a tool developed by the author to support the measuring process, is presented. The third part of the paper presents empirical results and discusses the experience gained in the application of the RMS tool.},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-030645739390079S-main.pdf:PDF},
}

@InProceedings{TheValueofSoftwareDocumentationQuality,
  author    = {Plösch, Reinhold and Dautovic, Andreas and Saft, Matthias},
  booktitle = {2014 14th International Conference on Quality Software},
  title     = {The Value of Software Documentation Quality},
  doi       = {10.1109/QSIC.2014.22},
  pages     = {333-342},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/The_Value_of_Software_Documentation_Quality.pdf:PDF},
  priority  = {prio1},
  year      = {2014},
}

@InProceedings{SoftwareDocumentationIssuesUnveiled,
  author    = {Aghajani, Emad and Nagy, Csaba and Vega-Márquez, Olga Lucero and Linares-Vásquez, Mario and Moreno, Laura and Bavota, Gabriele and Lanza, Michele},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE)},
  title     = {Software Documentation Issues Unveiled},
  doi       = {10.1109/ICSE.2019.00122},
  pages     = {1199-1210},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Software_Documentation_Issues_Unveiled.pdf:PDF},
  priority  = {prio1},
  year      = {2019},
}

@InProceedings{OpenSourceSoftwareDocumentationMiningforQualityAssessment,
  author    = {Nuno Ramos Carvalho and Alberto Sim{\~o}es and Jos{\'e} Jo{\~a}o Almeida},
  title     = {Open Source Software Documentation Mining for Quality Assessment},
  booktitle = {WorldCIST},
  year      = {2013},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/wcist2012-dmoss.pdf:PDF},
}

@Article{RecoveringTraceabilityLinksbetweenCodeandDocumentation,
  author  = {Antoniol, Giuliano and Canfora, Gerardo and Casazza, Gerardo and Lucia, Andrea and Merlo, Ettore},
  title   = {Recovering Traceability Links between Code and Documentation},
  journal = {Software Engineering, IEEE Transactions on},
  year    = {2002},
  volume  = {28},
  month   = {11},
  pages   = {970- 983},
  doi     = {10.1109/TSE.2002.1041053},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Antoniol02a.pdf:PDF},
}

@Article{AutomatedEvaluationofSourceCodeDocumentation:InterimReport,
  author = {Hirsch, Ben and Heines, Jesse},
  title  = {Automated Evaluation of Source Code Documentation: Interim Report},
  year   = {2008},
  month  = {07},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/Automated_Evaluation_of_Source_Code_Documentation_.pdf:PDF},
}

@Article{ANTLR:APredicated-<i>LLk</i>ParserGenerator,
  author     = {Parr, T. J. and Quong, R. W.},
  title      = {ANTLR: A predicated-LL(k) parser generator},
  doi        = {10.1002/spe.4380250705},
  issn       = {0038-0644},
  number     = {7},
  pages      = {789–810},
  volume     = {25},
  address    = {USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.57.881.pdf:PDF},
  issue_date = {July 1995},
  journal    = {Software: Practice and Experience},
  keywords   = {parsing, parser generator, compiler, predicates, LL(k) parser},
  month      = jul,
  numpages   = {22},
  priority   = {prio1},
  publisher  = {John Wiley \&amp; Sons, Inc.},
  year       = {1995},
}

@Article{ComparativeStudyoftheQualityAssessmentToolsBasedonaModel:SonarSqualeEvalMetrics,
  author  = {Bougroun, Zineb and Zeaaraoui, Adil and Toumi, Bouchentouf},
  title   = {Comparative Study of the Quality Assessment Tools Based on a Model: Sonar, Squale, EvalMetrics},
  journal = {Journal of Computer Science},
  year    = {2016},
  volume  = {12},
  month   = {01},
  pages   = {39-47},
  doi     = {10.3844/jcssp.2016.39.47},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/52-Article Text-100-1-10-20210516.pdf:PDF},
}

@InProceedings{Automaticassessmentofsoftwaredocumentationquality,
  author    = {Dautovic, Andreas},
  title     = {Automatic assessment of software documentation quality},
  booktitle = {2011 26th IEEE/ACM International Conference on Automated Software Engineering (ASE 2011)},
  year      = {2011},
  pages     = {665-669},
  doi       = {10.1109/ASE.2011.6100151},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Automatic_assessment_of_software_documentation_quality.pdf:PDF},
}

@Article{DMOSS:Opensourcesoftwaredocumentationassessment,
  author  = {Nuno Ramos Carvalho and Alberto Sim{\~o}es and Jos{\'e} Jo{\~a}o Almeida},
  title   = {DMOSS: Open source software documentation assessment},
  journal = {Comput. Sci. Inf. Syst.},
  year    = {2014},
  volume  = {11},
  pages   = {1197-1207},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/dmoss.pdf:PDF},
}

@Article{Softwaredocumentation,
  author  = {Sommerville, Ian},
  title   = {Software documentation},
  journal = {Software engineering},
  year    = {2001},
  volume  = {2},
  pages   = {143--154},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/documentation.pdf:PDF},
}

@InProceedings{HowDocumentationEvolvesoverTime,
  author    = {Schreck, Daniel and Dallmeier, Valentin and Zimmermann, Thomas},
  booktitle = {Ninth International Workshop on Principles of Software Evolution: In Conjunction with the 6th ESEC/FSE Joint Meeting},
  title     = {How Documentation Evolves over Time},
  doi       = {10.1145/1294948.1294952},
  isbn      = {978-1-59593-722-3},
  location  = {Dubrovnik, Croatia},
  pages     = {4–10},
  publisher = {Association for Computing Machinery},
  series    = {IWPSE '07},
  abstract  = {Good source code documentation, especially of programming interfaces, is essential
for using and maintaining software components. In this paper, we present the Quasoledo
tool that automatically measures the quality of documentation with respect to completeness,
quantity, and readability. We applied our set of metrics to the Eclipse project, and
benchmarked against the well-documented Java class library. The result of Quasoledo
is a map of documentation quality in Eclipse, showing the best documentation for its
core components. Additionally, we looked at the evolution of Eclipse and identified
batch updates that caused jumps in documentation quality. For Eclipse, only 32.6\%
of all changes touched documentation.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1294948.1294952.pdf:PDF},
  numpages  = {7},
  priority  = {prio1},
  year      = {2007},
}

@Article{SMSCQA:SystemforMeasuringSourceCodeQualityAssurance,
  author  = {Ayman, Hussein and Odeh, Ayman},
  title   = {SMSCQA: System for Measuring Source Code Quality Assurance},
  journal = {International Journal of Computer Applications},
  year    = {2012},
  volume  = {60},
  month   = {12},
  pages   = {975-8887},
  doi     = {10.5120/9714-4181},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.303.4758.pdf:PDF},
}

@InProceedings{JavadocViolationsandTheirEvolutioninOpen-SourceSoftware,
  author    = {Steinbeck, Marcel and Koschke, Rainer},
  booktitle = {2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  title     = {Javadoc Violations and Their Evolution in Open-Source Software},
  doi       = {10.1109/SANER50967.2021.00031},
  pages     = {249-259},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Javadoc_Violations_and_Their_Evolution_in_Open-Source_Software.pdf:PDF},
  priority  = {prio1},
  year      = {2021},
}

@InProceedings{Exstatic:AGenericStaticCheckerAppliedtoDocumentationSystems,
  author    = {Mount, S. N. I. and Newman, R. M. and Low, R. J. and Mycroft, A.},
  title     = {Exstatic: A Generic Static Checker Applied to Documentation Systems},
  booktitle = {Proceedings of the 22nd Annual International Conference on Design of Communication: The Engineering of Quality Documentation},
  year      = {2004},
  series    = {SIGDOC '04},
  publisher = {Association for Computing Machinery},
  location  = {Memphis, Tennessee, USA},
  isbn      = {1581138091},
  pages     = {52–57},
  doi       = {10.1145/1026533.1026548},
  url       = {https://doi.org/10.1145/1026533.1026548},
  abstract  = {Exstatic is a generic static checker developed by the author to address many of the
practical problems in program development. Static checking provides a valuable means
for automating time consuming checks not only concerned with program correctness (writing
the right program), but also to do with style (writing the program right). Previous
static checkers have been closely coupled with compilation systems, and therefore
tend to be applicable to the code itself and not to all of the textual information
(such as makefiles, comments, documentation sources) surrounding the code. The generic
nature of Exstatic allows it to overcome these boundaries, and indeed it can be applied
to any medium for which there is a formally definable syntax and (to an extent) semantics.
Exstatic can therefore be used to increase the productivity and quality of documentation
of programs, checking for such things as adherence to house style, consistency with
the program being documented and self consistency. This paper describes the design
and use of Exstatic, with particular reference to its use in documentation systems.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1026533.1026548.pdf:PDF},
  keywords  = {static checking, standards, javadoc, exstatic, docstrings},
  numpages  = {6},
}

@Article{ImplementingSourceCodeMetricsforSoftwarequalityanalysis,
  author  = {Mandeep K. Chawla and Indu Chhabra},
  title   = {Implementing Source Code Metrics for Software quality analysis},
  journal = {International journal of engineering research and technology},
  year    = {2012},
  volume  = {1},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/implementing-source-code-metrics-for-software-quality-analysis-IJERTV1IS5099.pdf:PDF},
}

@Article{CommentingonCodeConsideringDatasBottleneck,
  author     = {Torres, Edwin and Saba, Walid},
  title      = {Commenting on Code, Considering Data's Bottleneck},
  journal    = {Commun. ACM},
  year       = {2018},
  volume     = {61},
  number     = {5},
  month      = apr,
  pages      = {24–25},
  issn       = {0001-0782},
  doi        = {10.1145/3193752},
  url        = {https://doi.org/10.1145/3193752},
  abstract   = {The Communications Web site, http://cacm.acm.org, features more than a dozen bloggers
in the BLOG@CACM community. In each issue of Communications, we'll publish selected
posts or excerpts.twitterFollow us on Twitter at http://twitter.com/blogCACMhttp://cacm.acm.org/blogs/blog-cacmEdwin
Torres considers the enduring value of code comments, while Walid Saba wonders if
we have overreacted to the knowledge acquisition bottleneck.},
  address    = {New York, NY, USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/3193752.pdf:PDF},
  issue_date = {May 2018},
  numpages   = {2},
  publisher  = {Association for Computing Machinery},
}

@Article{StaticAnalysis:AnIntroduction:TheFundamentalChallengeofSoftwareEngineeringisOneofComplexity.,
  author     = {Thomson, Patrick},
  title      = {Static Analysis: An Introduction: The Fundamental Challenge of Software Engineering is One of Complexity.},
  doi        = {10.1145/3487019.3487021},
  issn       = {1542-7730},
  number     = {4},
  pages      = {29–41},
  volume     = {19},
  abstract   = {Modern static-analysis tools provide powerful and specific insights into codebases.
The Linux kernel team, for example, developed Coccinelle, a powerful tool for searching,
analyzing, and rewriting C source code; because the Linux kernel contains more than
27 million lines of code, a static-analysis tool is essential both for finding bugs
and for making automated changes across its many libraries and modules. Another tool
targeted at the C family of languages is Clang scan-build, which comes with many useful
analyses and provides an API for programmers to write their own analyses. Like so
many things in computer science, the utility of static analysis is self-referential:
To write reliable programs, we must also write programs for our programs. But this
is no paradox. Static-analysis tools, complex though their theory and practice may
be, are what will enable us, and engineers of the future, to overcome this challenge
and yield the knowledge and insights that we practitioners deserve.},
  address    = {New York, NY, USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/3487019.3487021.pdf:PDF},
  issue_date = {July-August 2021},
  journal    = {Queue},
  month      = aug,
  numpages   = {13},
  priority   = {prio1},
  publisher  = {Association for Computing Machinery},
  year       = {2021},
}

@Article{DocumentationTesting,
  author     = {Mamone, Salvatore},
  title      = {Documentation Testing},
  journal    = {SIGSOFT Softw. Eng. Notes},
  year       = {2000},
  volume     = {25},
  number     = {2},
  month      = mar,
  pages      = {26–29},
  issn       = {0163-5948},
  doi        = {10.1145/346057.346066},
  url        = {https://doi.org/10.1145/346057.346066},
  abstract   = {One definition of documentation is 'Any written or pictorial information describing,
defining, specifying, reporting, or certifying activities, requirements, procedures,
or results.' (1). Documentation is as important to a product's success as the product
itself. If the documentation is poor, non-existent, or wrong, it reflects on the quality
of the product and the vendor.At the Bell Atlantic Systems Integration &amp; Testing
Center documentation testing is an important function that receives as much attention
as the testing of software and hardware. Because the Bell Atlantic Systems Integration
&amp; Testing Center is ISO9001 certified, an enormous effort was undertaken to ensure
quality assurance of all products including documentation. Both a test procedure and
test plan for documentation has been implemented to ensure this quality.This article
will describe what documentation is, why document testing is important, and how document
testing is performed at the Bell Atlantic Systems Integration &amp; Testing Center.Other
information pertaining to documentation, such as human factors, how to achieve document
comprehensiveness, and comprehensibility, although important, are beyond the reach
of this report.},
  address    = {New York, NY, USA},
  file       = {:/home/compf/data/uni/sem7/bachelor/sources/346057.346066.pdf:PDF},
  issue_date = {March 2000},
  numpages   = {4},
  publisher  = {Association for Computing Machinery},
}

@Article{IEEEStandardGlossaryofSoftwareEngineeringTerminology,
  title    = {IEEE Standard Glossary of Software Engineering Terminology},
  doi      = {10.1109/IEEESTD.1990.101064},
  pages    = {1-84},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/61012-1990.pdf:PDF},
  journal  = {IEEE Std 610.12-1990},
  priority = {prio1},
  year     = {1990},
}

@Article{Softwaredocumentation:frominstructiontointegration,
  author  = {Barker, T.T.},
  title   = {Software documentation: from instruction to integration},
  journal = {IEEE Transactions on Professional Communication},
  year    = {1990},
  volume  = {33},
  number  = {4},
  pages   = {172-177},
  doi     = {10.1109/47.62811},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Software_documentation_from_instruction_to_integration.pdf:PDF},
}

@Article{Softwaredocumentationandstandards,
  author   = {J. M. Jose and T. Viswanathan},
  title    = {Software documentation and standards},
  pages    = {123-133},
  volume   = {39},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/ALIS 39(4) 123-133.pdf:PDF},
  journal  = {Annals of library science and documentation},
  priority = {prio1},
  year     = {1992},
}

@InProceedings{TheRelevanceofSoftwareDocumentationToolsandTechnologies:ASurvey,
  author    = {Forward, Andrew and Lethbridge, Timothy C.},
  booktitle = {Proceedings of the 2002 ACM Symposium on Document Engineering},
  title     = {The Relevance of Software Documentation, Tools and Technologies: A Survey},
  doi       = {10.1145/585058.585065},
  isbn      = {978-1-58113-594-7},
  location  = {McLean, Virginia, USA},
  pages     = {26–33},
  publisher = {Association for Computing Machinery},
  series    = {DocEng '02},
  abstract  = {This paper highlights the results of a survey of software professionals. One of the
goals of this survey was to uncover the perceived relevance (or lack thereof) of software
documentation, and the tools and technologies used to maintain, verify and validate
such documents. The survey results highlight the preferences for and aversions against
software documentation tools. Participants agree that documentation tools should seek
to better extract knowledge from core resources. These resources include the system's
source code, test code and changes to both. Resulting technologies could then help
reduce the effort required for documentation maintenance, something that is shown
to rarely occur. Our data reports compelling evidence that software professionals
value technologies that improve automation of the documentation process, as well as
facilitating its maintenance.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/585058.585065.pdf:PDF},
  keywords  = {software maintenance, software documentation, program comprehension, documentation survey, documentation technologies, documentation relevance, software engineering},
  numpages  = {8},
  priority  = {prio1},
  year      = {2002},
}

@Article{CostBenefitsandQualityofSoftwareDevelopmentDocumentation:ASystematicMapping,
  author  = {Zhi, Junji and Garousi, Vahid and Sun, Bo and Garousi, Golara and Shahnewaz, S. and Ruhe, Guenther},
  title   = {Cost, Benefits and Quality of Software Development Documentation: A Systematic Mapping},
  journal = {Journal of Systems and Software},
  year    = {2014},
  volume  = {99},
  month   = {01},
  doi     = {10.1016/j.jss.2014.09.042},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Cost Benefits and Quality of Software Development.pdf:PDF},
}

@WWW{Javadoc,
  title   = {Javadoc},
  url     = {https://www.oracle.com/technical-resources/articles/java/javadoc-tool.html},
  urldate = {2021-10-21},
}

@Misc{BeyondAccuracy:AssessingSoftwareDocumentationQuality,
  author        = {Christoph Treude and Justin Middleton and Thushari Atapattu},
  title         = {Beyond Accuracy: Assessing Software Documentation Quality},
  year          = {2020},
  eprint        = {2007.10744},
  archiveprefix = {arXiv},
  file          = {:/home/compf/data/uni/sem7/bachelor/sources/2007.10744.pdf:PDF},
  primaryclass  = {cs.SE},
}

@Misc{kuhn2013verifiable,
  author        = {Tobias Kuhn and Alexandre Bergel},
  title         = {Verifiable Source Code Documentation in Controlled Natural Language},
  year          = {2013},
  eprint        = {1311.2702},
  archiveprefix = {arXiv},
  file          = {:/home/compf/data/uni/sem7/bachelor/sources/1311.2702.pdf:PDF},
  primaryclass  = {cs.SE},
}

@InProceedings{10.1145/944868.944888,
  author    = {Huang, Shihong and Tilley, Scott},
  title     = {Towards a Documentation Maturity Model},
  booktitle = {Proceedings of the 21st Annual International Conference on Documentation},
  year      = {2003},
  series    = {SIGDOC '03},
  publisher = {Association for Computing Machinery},
  location  = {San Francisco, CA, USA},
  isbn      = {158113696X},
  pages     = {93–99},
  doi       = {10.1145/944868.944888},
  url       = {https://doi.org/10.1145/944868.944888},
  abstract  = {This paper presents preliminary work towards a maturity model for system documentation. The Documentation Maturity Model (DMM) is specifically targeted towards assessing the quality of documentation used in aiding program understanding. Software engineers and technical writers produce such documentation during regular product development lifecycles. The documentation can also be recreated after the fact via reverse engineering. The DMM has both process and product components; this paper focuses on the product quality aspects.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/944868.944888.pdf:PDF},
  keywords  = {documentation, reverse engineering, maturity model, quality},
  numpages  = {7},
}

@Article{Assessingthequalityfactorsfoundinin-linedocumentationwritteninnaturallanguage:TheJavadocMiner,
  author  = {Khamis, Ninus and Rilling, Juergen and Witte, René},
  title   = {Assessing the quality factors found in in-line documentation written in natural language: The JavadocMiner},
  journal = {Data \& Knowledge Engineering},
  year    = {2013},
  volume  = {87},
  month   = {09},
  pages   = {19–40},
  doi     = {10.1016/j.datak.2013.02.001},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-S0169023X13000207-main.pdf:PDF},
}

@InProceedings{10.1145/318372.318577,
  author    = {Kramer, Douglas},
  title     = {API Documentation from Source Code Comments: A Case Study of Javadoc},
  booktitle = {Proceedings of the 17th Annual International Conference on Computer Documentation},
  year      = {1999},
  series    = {SIGDOC '99},
  publisher = {Association for Computing Machinery},
  location  = {New Orleans, Louisiana, USA},
  isbn      = {1581130724},
  pages     = {147–153},
  doi       = {10.1145/318372.318577},
  url       = {https://doi.org/10.1145/318372.318577},
  abstract  = {This paper describes in a general way the process we went through to determine the goals, principles, audience, content and style for writing comments in source code for the Java platform at the Java Software division of Sun Microsystems. This includes how the documentation comments evolved to become the home of the Java platform API specification, and the guidelines we developed to make it practical for this document to reside in the same files as the source code.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/318372.318577.pdf:PDF},
  keywords  = {doc comments, Java platform, generated documentation, doclets, source code comments, documentation comments, API documentation, Javadoc},
  numpages  = {7},
}

@Article{LiterateProgramming,
  author   = {Knuth, D. E.},
  title    = {{Literate Programming}},
  journal  = {The Computer Journal},
  year     = {1984},
  volume   = {27},
  number   = {2},
  month    = {01},
  pages    = {97-111},
  issn     = {0010-4620},
  doi      = {10.1093/comjnl/27.2.97},
  abstract = {{The author and his associates have been experimenting for the past several years with a programming language and documentation system called WEB. This paper presents WEB by example, and discusses why the new system appears to be an improvement over previous ones.}},
}

@InProceedings{DoclasscommentsaidJavaprogramunderstanding?,
  author = {Nurvitadhi, E. and Leung, Wing and Cook, C.},
  title  = {Do class comments aid Java program understanding?},
  year   = {2003},
  volume = {1},
  month  = {12},
  isbn   = {0-7803-7961-6},
  pages  = {T3C-13},
  doi    = {10.1109/FIE.2003.1263332},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.87.6694.pdf:PDF},
}

@Article{2021,
  author    = {Rani, Pooja and Panichella, Sebastiano and Leuenberger, Manuel and Ghafari, Mohammad and Nierstrasz, Oscar},
  title     = {What do class comments tell us? An investigation of comment evolution and practices in Pharo Smalltalk},
  journal   = {Empirical Software Engineering},
  year      = {2021},
  volume    = {26},
  number    = {6},
  month     = {Aug},
  issn      = {1573-7616},
  doi       = {10.1007/s10664-021-09981-5},
  url       = {http://dx.doi.org/10.1007/s10664-021-09981-5},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Rani2021_Article_WhatDoClassCommentsTellUsAnInv.pdf:PDF},
  publisher = {Springer Science and Business Media LLC},
}

@InProceedings{Softwareengineeringandsoftwaredocumentation:aunifiedlongcourse,
  author    = {Young, F.H.},
  booktitle = {Proceedings Frontiers in Education Twenty-First Annual Conference. Engineering Education in a New World Order},
  title     = {Software engineering and software documentation: a unified long course},
  doi       = {10.1109/FIE.1991.187557},
  pages     = {593-595},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Software_engineering_and_software_documentation_a_unified_long_course.pdf:PDF},
  priority  = {prio1},
  year      = {1991},
}

@Article{TheRoleofDocumentationinProgrammerTraining-FromConventionalDocumentationtoLiterateProgrammingHypertextAndObject-OrientedDocumentation,
  author = {Sametinger, Johannes},
  title  = {The Role of Documentation in Programmer Training - From Conventional Documentation to Literate Programming, Hypertext And Object-Oriented Documentation},
  year   = {1995},
  month  = {06},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/The_Role_of_Documentation_in_Programmer_Training_-.pdf:PDF},
}

@InProceedings{TeachingPracticalSoftwareMaintenanceSkillsinaSoftwareEngineeringCourse,
  author    = {Collofello, J. S.},
  title     = {Teaching Practical Software Maintenance Skills in a Software Engineering Course},
  booktitle = {Proceedings of the Twentieth SIGCSE Technical Symposium on Computer Science Education},
  year      = {1989},
  series    = {SIGCSE '89},
  publisher = {Association for Computing Machinery},
  location  = {Louisville, Kentucky, USA},
  isbn      = {0897912985},
  pages     = {182–184},
  doi       = {10.1145/65293.71211},
  url       = {https://doi.org/10.1145/65293.71211},
  abstract  = {The typical one-semester software engineering course is normally geared towards new software development. Unfortunately, most new computer science graduates do not find themselves in a position where they are developing new software but instead in a position where they are maintaining an existing product. This paper describes some current practical software maintenance approaches which can be taught as a part of a software engineering course.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/65294.71211.pdf:PDF},
  numpages  = {3},
}

@InProceedings{10.1145/2931037.2931061,
  author    = {Goffi, Alberto and Gorla, Alessandra and Ernst, Michael D. and Pezz\`{e}, Mauro},
  booktitle = {Proceedings of the 25th International Symposium on Software Testing and Analysis},
  title     = {Automatic Generation of Oracles for Exceptional Behaviors},
  doi       = {10.1145/2931037.2931061},
  isbn      = {9781450343909},
  location  = {Saarbr\"{u}cken, Germany},
  pages     = {213–224},
  publisher = {Association for Computing Machinery},
  series    = {ISSTA 2016},
  url       = {https://doi.org/10.1145/2931037.2931061},
  abstract  = {Test suites should test exceptional behavior to detect faults in error-handling code. However, manually-written test suites tend to neglect exceptional behavior. Automatically-generated test suites, on the other hand, lack test oracles that verify whether runtime exceptions are the expected behavior of the code under test.  This paper proposes a technique that automatically creates test oracles for exceptional behaviors from Javadoc comments. The technique uses a combination of natural language processing and run-time instrumentation. Our implementation, Toradocu, can be combined with a test input generation tool. Our experimental evaluation shows that Toradocu improves the fault-finding effectiveness of EvoSuite and Randoop test suites by 8\% and 16\% respectively, and reduces EvoSuite’s false positives by 33\%.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/2931037.2931061.pdf:PDF},
  keywords  = {Testing, oracle generation, automatic test oracle, oracle problem},
  numpages  = {12},
  year      = {2016},
}

@InProceedings{IntelligentSoftwareDevelopmentEnvironments:IntegratingNaturalLanguageProcessingwiththeEclipsePlatform,
  author = {Witte, René and Sateli, Bahar and Khamis, Ninus and Rilling, Juergen},
  title  = {Intelligent Software Development Environments: Integrating Natural Language Processing with the Eclipse Platform},
  year   = {2011},
  month  = {05},
  isbn   = {978-3-642-21042-6},
  pages  = {408-419},
  doi    = {10.1007/978-3-642-21043-3_49},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/2011_Book_AdvancesInArtificialIntelligen.pdf:PDF},
}

@Article{Haque2021ActionWP,
  author  = {Sakib Haque and Aakash Bansal and Lingfei Wu and Collin McMillan},
  title   = {Action Word Prediction for Neural Source Code Summarization},
  journal = {2021 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER)},
  year    = {2021},
  pages   = {330--341},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Action_Word_Prediction_for_Neural_Source_Code_Summarization.pdf:PDF},
}

@Article{Csri2015ExaminingSC,
  author  = {Tam{\'a}s Cs{\'e}ri},
  title   = {Examining structural correctness of documentation comments in C++ programs},
  journal = {2015 IEEE 13th International Scientific Conference on Informatics},
  year    = {2015},
  pages   = {79-84},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Examining_structural_correctness_of_documentation_comments_in_C_programs.pdf:PDF},
}

@InProceedings{QualityoftheSourceCodeforDesignandArchitectureRecoveryTechniques:UtilitiesaretheProblem,
  author  = {Pirzadeh, Heidar and Alawneh, Luay and Hamou-Lhadj, Abdelwahab},
  title   = {Quality of the Source Code for Design and Architecture Recovery Techniques: Utilities are the Problem},
  year    = {2009},
  month   = {08},
  pages   = {465-469},
  doi     = {10.1109/QSIC.2009.69},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Quality_of_the_Source_Code_for_Design_and_Architecture_Recovery_Techniques_Utilities_are_the_Problem.pdf:PDF},
  journal = {Proceedings - International Conference on Quality Software},
}

@Article{HYATT1997223,
  author   = {Lawrence E. Hyatt and Linda H. Rosenberg},
  title    = {Software metrics program for risk assessment},
  journal  = {Acta Astronautica},
  year     = {1997},
  volume   = {40},
  number   = {2},
  pages    = {223-233},
  note     = {Enlarging The Scope of Space Applications},
  issn     = {0094-5765},
  doi      = {https://doi.org/10.1016/S0094-5765(97)00148-3},
  url      = {https://www.sciencedirect.com/science/article/pii/S0094576597001483},
  abstract = {The Software Assurance Technology Center (SATC) has developed a software metrics program consisting of goals, attributes and metrics to support the assessment of project status, risk, and product quality throughout the life cycle. The objective of the software metrics program is to assess risk areas at each phase of the development life cycle and project them into the future. The software development goals in the metrics program are evaluated by a set of attributes that help to define and classify risks. The attributes must be “measurable” by a set of metrics. These metrics must be based on data that is collectable within the confines of the software development process and must also be relevant to the quality attributes and risk assessment. This paper discusses the SATC's software risk assessment metrics program which meets these needs and is currently being applied to software developed for NASA. At each phase of the software development life cycle, attributes will be identified and metrics defined. Project data is used to demonstrate how the metric analysis was applied at that phase for risk assessment, and how that information could be used by management to manage project risks.},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-S0094576597001483-main.pdf:PDF},
}

@Article{HowSoftwareEngineersUseDocumentation:TheStateofthePractice,
  author  = {Lethbridge, Timothy and Singer, Janice and Forward, Andrew},
  title   = {How Software Engineers Use Documentation: The State of the Practice},
  journal = {Software, IEEE},
  year    = {2003},
  volume  = {20},
  month   = {12},
  pages   = {35 - 39},
  doi     = {10.1109/MS.2003.1241364},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Lethbridge-Singer-Forward-2003.pdf:PDF},
}

@InProceedings{Reusabilityandmaintainabilitymetricsforobject-orientedsoftware,
  author = {Lee, Young and Chang, Kai},
  title  = {Reusability and maintainability metrics for object-oriented software},
  year   = {2000},
  month  = {01},
  pages  = {88-94},
  doi    = {10.1145/1127716.1127737},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/1127716.1127737.pdf:PDF},
}

@Article{Studytheimpactofimprovingsourcecodeonsoftwaremetrics,
  author = {Zoubi, Qosai and Alsmadi, Izzat and Abul-Huda, B.},
  title  = {Study the impact of improving source code on software metrics},
  year   = {2012},
  month  = {05},
  doi    = {10.1109/CITS.2012.6220379},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/1127716.1127737.pdf:PDF},
}

@Article{PredictingJavaSourceCodePropertiesfromaNaturalLanguageSpecification,
  author = {Turner, Kathy and Cardin, Pascal and Reid, Sam and Clawson, Joel},
  title  = {Predicting Java Source Code Properties from a Natural Language Specification},
  year   = {2021},
  month  = {11},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/10.1.1.91.3692.pdf:PDF},
}

@WWW{HowtoWriteDocCommentsfortheJavadocTool,
  title    = {How to Write Doc Comments for the Javadoc Tool},
  url      = {https://www.oracle.com/de/technical-resources/articles/java/javadoc-tool.html},
  urldate  = {2021-12-16},
  journal  = {How to Write Doc Comments for the Javadoc Tool | Oracle Deutschland},
  priority = {prio1},
}

@Book{martin2009clean,
  author    = {Martin, Robert C},
  title     = {Clean code: a handbook of agile software craftsmanship},
  isbn      = {978-0-1323-5088-4},
  publisher = {Pearson Education},
  priority  = {prio1},
  year      = {2009},
}

@InProceedings{10.1145/1858996.1859006,
  author    = {Sridhara, Giriprasad and Hill, Emily and Muppaneni, Divya and Pollock, Lori and Vijay-Shanker, K.},
  title     = {Towards Automatically Generating Summary Comments for Java Methods},
  booktitle = {Proceedings of the IEEE/ACM International Conference on Automated Software Engineering},
  year      = {2010},
  series    = {ASE '10},
  publisher = {Association for Computing Machinery},
  location  = {Antwerp, Belgium},
  isbn      = {9781450301169},
  pages     = {43–52},
  doi       = {10.1145/1858996.1859006},
  url       = {https://doi.org/10.1145/1858996.1859006},
  abstract  = {Studies have shown that good comments can help programmers quickly understand what a method does, aiding program comprehension and software maintenance. Unfortunately, few software projects adequately comment the code. One way to overcome the lack of human-written summary comments, and guard against obsolete comments, is to automatically generate them. In this paper, we present a novel technique to automatically generate descriptive summary comments for Java methods. Given the signature and body of a method, our automatic comment generator identifies the content for the summary and generates natural language text that summarizes the method's overall actions. According to programmers who judged our generated comments, the summaries are accurate, do not miss important content, and are reasonably concise.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1858996.1859006.pdf:PDF},
  keywords  = {natural language program analysis, comment generation, method summarization},
  numpages  = {10},
}

@InProceedings{10.1145/1159733.1159738,
  author    = {Arisholm, Erik and Briand, Lionel C.},
  title     = {Predicting Fault-Prone Components in a Java Legacy System},
  booktitle = {Proceedings of the 2006 ACM/IEEE International Symposium on Empirical Software Engineering},
  year      = {2006},
  series    = {ISESE '06},
  publisher = {Association for Computing Machinery},
  location  = {Rio de Janeiro, Brazil},
  isbn      = {1595932186},
  pages     = {8–17},
  doi       = {10.1145/1159733.1159738},
  url       = {https://doi.org/10.1145/1159733.1159738},
  abstract  = {This paper reports on the construction and validation of faultproneness prediction models in the context of an object-oriented, evolving, legacy system. The goal is to help QA engineers focus their limited verification resources on parts of the system likely to contain faults. A number of measures including code quality, class structure, changes in class structure, and the history of class-level changes and faults are included as candidate predictors of class fault-proneness. A cross-validated classification analysis shows that the obtained model has less than 20\% of false positives and false negatives, respectively. However, as shown in this paper, statistics regarding the classification accuracy tend to inflate the potential usefulness of the fault-proneness prediction models. We thus propose a simple and pragmatic methodology for assessing the costeffectiveness of the predictions to focus verification effort. On the basis of the cost-effectiveness analysis we show that change and fault data from previous releases is paramount to developing a practically useful prediction model. When our model is applied to predict faults in a new release, the estimated potential savings in verification effort is about 29\%. In contrast, the estimated savings in verification effort drops to 0\% when history data is not included.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1159733.1159738.pdf:PDF},
  numpages  = {10},
}

@InProceedings{7332619,
  author    = {Maldonado, Everton da S. and Shihab, Emad},
  title     = {Detecting and quantifying different types of self-admitted technical Debt},
  booktitle = {2015 IEEE 7th International Workshop on Managing Technical Debt (MTD)},
  year      = {2015},
  pages     = {9-15},
  doi       = {10.1109/MTD.2015.7332619},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Detecting_and_quantifying_different_types_of_self-admitted_technical_Debt.pdf:PDF},
}

@InProceedings{AnalyzingProgramComprehensibilityofGoProjects,
  author = {Asad, Moumita and Yasir, Rafed and Shahriar, Shihab and Nahar, Nadia and Tawhid, Md. Nurul Ahad},
  title  = {Analyzing Program Comprehensibility of Go Projects},
  year   = {2021},
  month  = {07},
  file   = {:/home/compf/data/uni/sem7/bachelor/sources/paper152.pdf:PDF},
}

@Article{5332232,
  author  = {Buse, Raymond P.L. and Weimer, Westley R.},
  title   = {Learning a Metric for Code Readability},
  journal = {IEEE Transactions on Software Engineering},
  year    = {2010},
  volume  = {36},
  number  = {4},
  pages   = {546-558},
  doi     = {10.1109/TSE.2009.70},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/Learning_a_Metric_for_Code_Readability.pdf:PDF},
}

@Article{CHEN201945,
  author   = {Huanchao Chen and Yuan Huang and Zhiyong Liu and Xiangping Chen and Fan Zhou and Xiaonan Luo},
  title    = {Automatically detecting the scopes of source code comments},
  journal  = {Journal of Systems and Software},
  year     = {2019},
  volume   = {153},
  pages    = {45-63},
  issn     = {0164-1212},
  doi      = {https://doi.org/10.1016/j.jss.2019.03.010},
  url      = {https://www.sciencedirect.com/science/article/pii/S016412121930055X},
  abstract = {Comments convey useful information about the system functionalities and many methods for software engineering tasks take comments as an important source for many software engineering tasks such as code semantic analysis, code reuse and so on. However, unlike structural doc comments, it is challenging to identify the relationship between the functional semantics of the code and its corresponding textual descriptions nested inside the code and apply it to automatic analyzing and mining approaches in software engineering tasks efficiently. In this paper, we propose a general method for the detection of source code comment scopes. Based on machine learning, our method utilized features of code snippets and comments to detect the scopes of source code comments automatically in Java programs. On the dataset of comment-statement pairs from 4 popular open source projects, our method achieved a high accuracy of 81.45\% in detecting the scopes of comments. Furthermore, the results demonstrated the feasibility and effectiveness of our comment scope detection method on new projects. Moreover, our method was applied to two specific software engineering tasks in our studies: analyzing software repositories for outdated comment detection and mining software repositories for comment generation. As a general approach, our method provided a solution to comment-code mapping. It improved the performance of baseline methods in both tasks, which demonstrated that our method is conducive to automatic analyzing and mining approaches on software repositories.},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/1-s2.0-S016412121930055X-main.pdf:PDF},
  keywords = {Comment scope detection, Machine learning, Software repositories},
}

@InProceedings{10.1145/1555860.1555866,
  author    = {Cifuentes, Cristina and Hoermann, Christian and Keynes, Nathan and Li, Lian and Long, Simon and Mealy, Erica and Mounteney, Michael and Scholz, Bernhard},
  title     = {BegBunch: Benchmarking for C Bug Detection Tools},
  booktitle = {Proceedings of the 2nd International Workshop on Defects in Large Software Systems: Held in Conjunction with the ACM SIGSOFT International Symposium on Software Testing and Analysis (ISSTA 2009)},
  year      = {2009},
  series    = {DEFECTS '09},
  publisher = {Association for Computing Machinery},
  location  = {Chicago, Illinois},
  isbn      = {9781605586540},
  pages     = {16–20},
  doi       = {10.1145/1555860.1555866},
  url       = {https://doi.org/10.1145/1555860.1555866},
  abstract  = {Benchmarks for bug detection tools are still in their infancy. Though in recent years various tools and techniques were introduced, little effort has been spent on creating a benchmark suite and a harness for a consistent quantitative and qualitative performance measurement. For assessing the performance of a bug detection tool and determining which tool is better than another for the type of code to be looked at, the following questions arise: 1) how many bugs are correctly found, 2) what is the tool's average false positive rate, 3) how many bugs are missed by the tool altogether, and 4) does the tool scale.In this paper we present our contribution to the C bug detection community: two benchmark suites that allow developers and users to evaluate accuracy and scalability of a given tool. The two suites contain buggy, mature open source code; bugs are representative of "real world" bugs. A harness accompanies each benchmark suite to compute automatically qualitative and quantitative performance of a bug detection tool.BegBunch has been tested to run on the Solaris™, Mac OS X and Linux operating systems. We show the generality of the harness by evaluating it with our own Parfait and three publicly available bug detection tools developed by others.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1555860.1555866.pdf:PDF},
  keywords  = {accuracy, scalability},
  numpages  = {5},
}

@InProceedings{883030,
  author    = {Godfrey and Qiang Tu},
  title     = {Evolution in open source software: a case study},
  booktitle = {Proceedings 2000 International Conference on Software Maintenance},
  year      = {2000},
  pages     = {131-142},
  doi       = {10.1109/ICSM.2000.883030},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Evolution_in_open_source_software_a_case_study.pdf:PDF},
}

@Article{Aggarwal2002AnIM,
  author  = {K. K. Aggarwal and Yogesh Singh and Jitender Kumar Chhabra},
  title   = {An integrated measure of software maintainability},
  journal = {Annual Reliability and Maintainability Symposium. 2002 Proceedings (Cat. No.02CH37318)},
  year    = {2002},
  pages   = {235-241},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/An_integrated_measure_of_software_maintainability.pdf:PDF},
}

@WWW{Minimatch,
  title    = {Minimatch},
  url      = {https://github.com/isaacs/minimatch},
  urldate  = {2021-12-16},
  priority = {prio1},
}

@WWW{antlr_grammar_github,
  url     = {https://github.com/antlr/grammars-v4/tree/master/java/java},
  urldate = {2021-12-16},
}

@InProceedings{Doautomaticrefactoringsimprovemaintainability?Anindustrialcasestudy,
  author    = {Szőke, Gábor and Nagy, Csaba and Hegedűs, Péter and Ferenc, Rudolf and Gyimóthy, Tibor},
  title     = {Do automatic refactorings improve maintainability? An industrial case study},
  booktitle = {2015 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  year      = {2015},
  pages     = {429-438},
  doi       = {10.1109/ICSM.2015.7332494},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/Do_automatic_refactorings_improve_maintainability_An_industrial_case_study.pdf:PDF},
}

@InProceedings{OntheUseofPropertiesinJavaApplications,
  author    = {Lumpe, Markus and Mahmud, Samiran and Vasa, Rajesh},
  title     = {On the Use of Properties in Java Applications},
  booktitle = {2010 21st Australian Software Engineering Conference},
  year      = {2010},
  pages     = {235-244},
  doi       = {10.1109/ASWEC.2010.35},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/On_the_Use_of_Properties_in_Java_Applications.pdf:PDF},
}

@WWW{javabeans,
  author  = {Sun Microsystems},
  url     = {https://download.oracle.com/otndocs/jcp/7224-javabeans-1.01-fr-spec-oth-JSpec/},
  urldate = {2021-12-16},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/beans.101.pdf:PDF},
}

@WWW{Java-parser,
  title    = {Java-parser},
  url      = {https://www.npmjs.com/package/java-parser},
  urldate  = {2021-12-01},
  priority = {prio1},
}

@Misc{gholba2012measures,
  author = {Gholba, MJ},
  title  = {Measures of Central Tendency},
  year   = {2012},
  file   = {:Measures of Central Tendency.pdf:PDF},
}

@Article{YAGER199835,
  author   = {Ronald R. Yager},
  title    = {Fusion of ordinal information using weighted median aggregation},
  issn     = {0888-613X},
  number   = {1},
  pages    = {35-52},
  url      = {https://www.sciencedirect.com/science/article/pii/S0888613X97100032},
  volume   = {18},
  abstract = {The weighted median is introduced as a fusion operation which can be used in situations in which, while having numeric values for the weights associated with the objects to be fused, the actual objects being fused only satisfy an ordering property. After introducing the concept of weighted median we compare it with the weighted average and show that they have many properties in common. We then provide an algorithm for learning the weights associated with a median aggregation. We then show how we can use this technique to extend the applicability of the Ordered Weighted Averaging (OWA) operator to situations in which the arguments are nonnumeric. Finally we show how we can use the weighted median as an alternative to the expected value in the evaluation of probabilistic lotteries.},
  file     = {:/home/compf/1-s2.0-S0888613X97100032-main.pdf:PDF},
  journal  = {International Journal of Approximate Reasoning},
  priority = {prio1},
  year     = {1998},
}

@Book{TheDefinitiveANTLR4Reference,
  author    = {Parr, Terence},
  title     = {The Definitive ANTLR 4 Reference},
  edition   = {2nd},
  isbn      = {978-1-934356-99-9},
  publisher = {Pragmatic Bookshelf},
  abstract  = {Programmers run into parsing problems all the time. Whether it's a data format like JSON, a network protocol like SMTP, a server configuration file for Apache, a PostScript/PDF file, or a simple spreadsheet macro language--ANTLR v4 and this book will demystify the process. ANTLR v4 has been rewritten from scratch to make it easier than ever to build parsers and the language applications built on top. This completely rewritten new edition of the bestselling Definitive ANTLR Reference shows you how to take advantage of these new features. Build your own languages with ANTLR v4, using ANTLR's new advanced parsing technology. In this book, you'll learn how ANTLR automatically builds a data structure representing the input (parse tree) and generates code that can walk the tree (visitor). You can use that combination to implement data readers, language interpreters, and translators. You'll start by learning how to identify grammar patterns in language reference manuals and then slowly start building increasingly complex grammars. Next, you'll build applications based upon those grammars by walking the automatically generated parse trees. Then you'll tackle some nasty language problems by parsing files containing more than one language (such as XML, Java, and Javadoc). You'll also see how to take absolute control over parsing by embedding Java actions into the grammar. You'll learn directly from well-known parsing expert Terence Parr, the ANTLR creator and project lead. You'll master ANTLR grammar construction and learn how to build language tools using the built-in parse tree visitor mechanism. The book teaches using real-world examples and shows you how to use ANTLR to build such things as a data file reader, a JSON to XML translator, an R parser, and a Java class-interface extractor. This book is your ticket to becoming a parsing guru!What You Need: ANTLR 4.0 and above. Java development tools. Ant build system optional (needed for building ANTLR from source)},
  priority  = {prio1},
  year      = {2013},
}

@InProceedings{icomment,
  author    = {Tan, Lin and Yuan, Ding and Krishna, Gopal and Zhou, Yuanyuan},
  booktitle = {Proceedings of Twenty-First ACM SIGOPS Symposium on Operating Systems Principles},
  title     = {/*icomment: Bugs or Bad Comments?*/},
  doi       = {10.1145/1294261.1294276},
  isbn      = {978-1-59593-591-5},
  location  = {Stevenson, Washington, USA},
  pages     = {145–158},
  publisher = {Association for Computing Machinery},
  series    = {SOSP '07},
  abstract  = {Commenting source code has long been a common practice in software development. Compared to source code, comments are more direct, descriptive and easy-to-understand. Comments and sourcecode provide relatively redundant and independent information regarding a program's semantic behavior. As software evolves, they can easily grow out-of-sync, indicating two problems: (1) bugs -the source code does not follow the assumptions and requirements specified by correct program comments; (2) bad comments - comments that are inconsistent with correct code, which can confuse and mislead programmers to introduce bugs in subsequent versions. Unfortunately, as most comments are written in natural language, no solution has been proposed to automatically analyze commentsand detect inconsistencies between comments and source code. This paper takes the first step in automatically analyzing commentswritten in natural language to extract implicit program rulesand use these rules to automatically detect inconsistencies between comments and source code, indicating either bugs or bad comments. Our solution, iComment, combines Natural Language Processing(NLP), Machine Learning, Statistics and Program Analysis techniques to achieve these goals. We evaluate iComment on four large code bases: Linux, Mozilla, Wine and Apache. Our experimental results show that iComment automatically extracts 1832 rules from comments with 90.8-100\% accuracy and detects 60 comment-code inconsistencies, 33 newbugs and 27 bad comments, in the latest versions of the four programs. Nineteen of them (12 bugs and 7 bad comments) have already been confirmed by the corresponding developers while the others are currently being analyzed by the developers.},
  address   = {New York, NY, USA},
  keywords  = {programming rules and static analysis, natural language processing for software engineering, comment analysis},
  numpages  = {14},
  priority  = {prio1},
  year      = {2007},
}

@InProceedings{InferringResourceSpecificationsfromNaturalLanguageAPIDocumentation,
  author    = {Zhong, Hao and Zhang, Lu and Xie, Tao and Mei, Hong},
  booktitle = {2009 IEEE/ACM International Conference on Automated Software Engineering},
  title     = {Inferring Resource Specifications from Natural Language API Documentation},
  doi       = {10.1109/ASE.2009.94},
  pages     = {307-318},
  year      = {2009},
}

@Article{ThePrinciplesofReadability,
  author   = {Dubay, William},
  title    = {The Principles of Readability},
  pages    = {631-3309},
  volume   = {92627949},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/The_Principles_of_Readability.pdf:PDF},
  journal  = {CA},
  month    = {01},
  priority = {prio1},
  year     = {2004},
}

@WWW{ncc,
  title    = {NCC},
  url      = {https://github.com/vercel/ncc},
  urldate  = {2021-12-16},
  priority = {prio1},
}

@WWW{Branch-Push,
  title    = {Branch-Push},
  url      = {https://github.com/ActionwareIO/branch-push-action},
  urldate  = {2022-02-22},
  priority = {prio1},
}

@Book{gamma2015design,
  author    = {Gamma, E. and Helm, R. and Johnson, R. and Vlissides, J.},
  title     = {Design Patterns: Entwurfsmuster als Elemente wiederverwendbarer objektorientierter Software},
  isbn      = {978-3-8266-9700-5},
  publisher = {MITP-Verlags GmbH \& Co. KG},
  series    = {mitp Professional},
  priority  = {prio1},
  year      = {2015},
}

@InProceedings{Fakhoury2018,
  author    = {Fakhoury, Sarah and Ma, Yuzhan and Arnaoudova, Venera and Adesope, Olusola},
  booktitle = {2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC)},
  date      = {2018},
  title     = {The Effect of Poor Source Code Lexicon and Readability on Developers' Cognitive Load},
  doi       = {10.1145/3196321.3196347},
  pages     = {286-296},
}

@InProceedings{vestdam,
  author    = {Vestdam, Thomas},
  booktitle = {EuroPLoP},
  date      = {2001-01},
  title     = {Writing Internal Documentation.},
  pages     = {511-534},
  priority  = {prio1},
}

@Book{fowler2019refactoring,
  author    = {Fowler, M. and Beck, K.},
  date      = {2019},
  title     = {Refactoring: Improving the Design of Existing Code},
  isbn      = {978-0-13-475759-9},
  publisher = {Addison-Wesley},
  series    = {A Martin Fowler signature book},
  lccn      = {2018950015},
  priority  = {prio1},
}

@InProceedings{Ray2014,
  author    = {Ray, Baishakhi and Posnett, Daryl and Filkov, Vladimir and Devanbu, Premkumar},
  booktitle = {Proceedings of the 22nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
  date      = {2014},
  title     = {A Large Scale Study of Programming Languages and Code Quality in Github},
  doi       = {10.1145/2635868.2635922},
  isbn      = {978-1-4503-3056-5},
  location  = {Hong Kong, China},
  pages     = {155–165},
  publisher = {Association for Computing Machinery},
  series    = {FSE 2014},
  abstract  = {What is the effect of programming languages on software quality? This question has been a topic of much debate for a very long time. In this study, we gather a very large data set from GitHub (729 projects, 80 Million SLOC, 29,000 authors, 1.5 million commits, in 17 languages) in an attempt to shed some empirical light on this question. This reasonably large sample size allows us to use a mixed-methods approach, combining multiple regression modeling with visualization and text analytics, to study the effect of language features such as static v.s. dynamic typing, strong v.s. weak typing on software quality. By triangulating findings from different methods, and controlling for confounding effects such as team size, project size, and project history, we report that language design does have a significant, but modest effect on software quality. Most notably, it does appear that strong typing is modestly better than weak typing, and among functional languages, static typing is also somewhat better than dynamic typing. We also find that functional languages are somewhat better than procedural languages. It is worth noting that these modest effects arising from language design are overwhelmingly dominated by the process factors such as project size, team size, and commit size. However, we hasten to caution the reader that even these modest effects might quite possibly be due to other, intangible process factors, e.g., the preference of certain personality types for functional, static and strongly typed languages.},
  address   = {New York, NY, USA},
  keywords  = {programming language, software domain, code quality, type system, empirical research, regression analysis, bug fix},
  numpages  = {11},
  priority  = {prio1},
}

@InProceedings{Vassallo2016,
  author    = {Vassallo, Carmine and Zampetti, Fiorella and Romano, Daniele and Beller, Moritz and Panichella, Annibale and Di Penta, Massimiliano and Zaidman, Andy},
  booktitle = {2016 IEEE International Conference on Software Maintenance and Evolution (ICSME)},
  date      = {2016},
  title     = {Continuous Delivery Practices in a Large Financial Organization},
  doi       = {10.1109/ICSME.2016.72},
  pages     = {519-528},
  priority  = {prio1},
}

@Article{ANormalizedLevenshteinDistanceMetric,
  author  = {Yujian, Li and Bo, Liu},
  title   = {A Normalized Levenshtein Distance Metric},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  year    = {2007},
  volume  = {29},
  number  = {6},
  pages   = {1091-1095},
  doi     = {10.1109/TPAMI.2007.1078},
  file    = {:/home/compf/data/uni/sem7/bachelor/sources/A_Normalized_Levenshtein_Distance_Metric.pdf:PDF},
}

@WWW{docstring,
  title    = {Docstring},
  url      = {https://www.python.org/dev/peps/pep-0257/},
  urldate  = {2022-02-22},
  priority = {prio1},
}

@WWW{doxygen,
  title    = {Doxygen},
  url      = {https://www.doxygen.nl/manual/docblocks.html},
  urldate  = {2022-02-22},
  priority = {prio1},
}

@WWW{javadoc_coding_standards,
  author   = {Stephen Colebourne},
  title    = {Javadoc coding standards},
  url      = {https://blog.joda.org/2012/11/javadoc-coding-standards.html},
  urldate  = {2022-02-22},
  priority = {prio1},
}

@InProceedings{Youcantcontroltheunfamiliar:Astudyontherelationsbetweenaggregationtechniquesforsoftwaremetrics,
  author    = {Vasilescu, Bogdan and Serebrenik, Alexander and van den Brand, Mark},
  booktitle = {2011 27th IEEE International Conference on Software Maintenance (ICSM)},
  title     = {You can't control the unfamiliar: A study on the relations between aggregation techniques for software metrics},
  doi       = {10.1109/ICSM.2011.6080798},
  pages     = {313-322},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/You_cant_control_the_unfamiliar_A_study_on_the_relations_between_aggregation_techniques_for_software_metrics.pdf:PDF},
  priority  = {prio1},
  year      = {2011},
}

@Article{Softwarequalitymetricsaggregationinindustry,
  author   = {Mordal, Karine and Anquetil, Nicolas and Laval, Jannik and Serebrenik, Alexander and Vasilescu, Bogdan and Ducasse, Stéphane},
  title    = {Software quality metrics aggregation in industry},
  doi      = {https://doi.org/10.1002/smr.1558},
  number   = {10},
  pages    = {1117-1135},
  volume   = {25},
  abstract = {SUMMARY With the growing need for quality assessment of entire software systems in the industry, new issues are emerging. First, because most software quality metrics are defined at the level of individual software components, there is a need for aggregation methods to summarize the results at the system level. Second, because a software evaluation requires the use of different metrics, with possibly widely varying output ranges, there is a need to combine these results into a unified quality assessment. In this paper we derive, from our experience on real industrial cases and from the scientific literature, requirements for an aggregation method. We then present a solution through the Squale model for metric aggregation, a model specifically designed to address the needs of practitioners. We empirically validate the adequacy of Squale through experiments on Eclipse. Additionally, we compare the Squale model to both traditional aggregation techniques (e.g., the arithmetic mean), and to econometric inequality indices (e.g., the Gini or the Theil indices), recently applied to aggregation of software metrics. Copyright © 2012 John Wiley \& Sons, Ltd.},
  file     = {:/home/compf/data/uni/sem7/bachelor/sources/J Software Evolu Process - 2012 - Mordal - Software quality metrics aggregation in industry.pdf:PDF},
  journal  = {Journal of Software: Evolution and Process},
  keywords = {software metrics, software quality, aggregation, inequality indices},
  priority = {prio1},
  year     = {2013},
}

@InProceedings{AnEmpiricalModelforContinuousandWeightedMetricAggregation,
  author    = {Mordal-Manet, Karine and Laval, Jannik and Ducasse, Stephane and Anquetil, Nicolas and Balmas, Francoise and Bellingard, Fabrice and Bouhier, Laurent and Vaillergues, Philippe and McCabe, Thomas J.},
  booktitle = {2011 15th European Conference on Software Maintenance and Reengineering},
  title     = {An Empirical Model for Continuous and Weighted Metric Aggregation},
  doi       = {10.1109/CSMR.2011.20},
  pages     = {141-150},
  priority  = {prio1},
  year      = {2011},
}

@Article{bogert1985defense,
  author    = {Bogert, Judith},
  title     = {In defense of the Fog Index},
  number    = {2},
  pages     = {9--12},
  volume    = {48},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/108056998504800203.pdf:PDF},
  journal   = {The Bulletin of the Association for Business Communication},
  priority  = {prio1},
  publisher = {Sage Publications Sage CA: Thousand Oaks, CA},
  year      = {1985},
}

@InProceedings{AStudyoftheDocumentationEssentialtoSoftwareMaintenance,
  author    = {de Souza, Sergio Cozzetti B. and Anquetil, Nicolas and de Oliveira, K\'{a}thia M.},
  title     = {A Study of the Documentation Essential to Software Maintenance},
  booktitle = {Proceedings of the 23rd Annual International Conference on Design of Communication: Documenting \& Designing for Pervasive Information},
  year      = {2005},
  series    = {SIGDOC '05},
  publisher = {Association for Computing Machinery},
  location  = {Coventry, United Kingdom},
  isbn      = {978-1-58113-594-7},
  pages     = {68–75},
  doi       = {10.1145/1085313.1085331},
  abstract  = {Software engineering has been striving for years to improve the practice of software development and maintenance. Documentation has long been prominent on the list of recommended practices to improve development and help maintenance. Recently however, agile methods started to shake this view, arguing that the goal of the game is to produce software and that documentation is only useful as long as it helps to reach this goal.On the other hand, in the re-engineering field, people wish they could re-document useful legacy software so that they may continue maintain them or migrate them to new platform.In these two case, a crucial question arises: "How much documentation is enough?" In this article, we present the results of a survey of software maintainers to try to establish what documentation artifacts are the most useful to them.},
  address   = {New York, NY, USA},
  file      = {:/home/compf/data/uni/sem7/bachelor/sources/1085313.1085331.pdf:PDF},
  keywords  = {software maintenance, empirical study, software system documentation, program understanding},
  numpages  = {8},
}

@WWW{add_commit,
  title    = {Add and commit},
  url      = {https://github.com/EndBug/add-and-commit},
  urldate  = {2022-02-17},
  priority = {prio1},
}

@Book{github_action_book,
  author    = {Chaminda Chandrasekara Pushpa Herath},
  title     = {Hands-on GitHub Actions},
  doi       = {https://doi.org/10.1007/978-1-4842-6464-5},
  edition   = {1},
  isbn      = {978-1-4842-6464-5},
  pagetotal = {162},
  publisher = {Apress, Berkeley, CA},
  subtitle  = {Implement CI/CD with GitHub Action Workflows for Your Applications},
  priority  = {prio1},
  year      = {2021},
}

@WWW{checkstyle_doc_metrics,
  title    = {Checkstyle Javadoc-Metriken},
  url      = {https://checkstyle.sourceforge.io/config_javadoc.html},
  urldate  = {2022-02-22},
  priority = {prio1},
}

@Article{pfleeger1992using,
  author    = {Pfleeger, Shari Lawrence and Fitzgerald, Joseph C and Rippy, Dale A},
  title     = {Using multiple metrics for analysis of improvement},
  doi       = {https://doi.org/10.1007/BF01720167},
  number    = {1},
  pages     = {27--36},
  volume    = {1},
  journal   = {Software Quality Journal},
  publisher = {Springer},
  year      = {1992},
}

@WWW{github_popular,
  author   = {Matt Asay},
  date     = {2021-07-30},
  title    = {Microsoft CEO accidentally underplays GitHub’s pervasiveness},
  url      = {https://www.techrepublic.com/article/microsoft-ceo-accidentally-underplays-githubs-pervasiveness/},
  urldate  = {2022-02-24},
  priority = {prio1},
}

@InProceedings{@tComment:TestingJavadocCommentstoDetectComment-CodeInconsistencies,
  author    = {Tan, Shin Hwei and Marinov, Darko and Tan, Lin and Leavens, Gary T.},
  booktitle = {2012 IEEE Fifth International Conference on Software Testing, Verification and Validation},
  title     = {@tComment: Testing Javadoc Comments to Detect Comment-Code Inconsistencies},
  doi       = {10.1109/ICST.2012.106},
  pages     = {260-269},
  priority  = {prio1},
  year      = {2012},
}

@WWW{node_java_speed,
  author   = {Alexandra Chikina and Andrej Suschevich},
  date     = {2019-07-15},
  title    = {Node.js vs Java: Why Compare?},
  url      = {https://intexsoft.com/blog/node-js-vs-java-why-compare/},
  urldate  = {2022-03-09},
  priority = {prio1},
  year     = {2019},
}

@WWW{javascript,
  title   = {JavaScript-Referenz},
  url     = {https://developer.mozilla.org/en-US/docs/Web/JavaScript},
  urldate = {2022-03-28},
}

@WWW{typescript,
  title   = {Typescript-Referenz},
  url     = {https://www.typescriptlang.org/docs/},
  urldate = {2022-03-28},
}

@WWW{nodejs,
  title   = {Node.js Webseite},
  urldate = {2022-03-28},
}

@WWW{eclipsejdt,
  title   = {Eclipse JDT Quellcode},
  url     = {https://github.com/eclipse/aspectj.eclipse.jdt.core/tree/37759146f8c5e68e69b19258bc31a8c812e8afb7/org.eclipse.jdt.core},
  urldate = {2022-04-05},
}

@WWW{argouml,
  title   = {ArgoUML Quellcode},
  url     = {https://github.com/argouml-tigris-org/argouml/tree/3ddc7f94d83c4e2f439ca6fc0fe787616a1900a9/src},
  urldate = {2022-04-05},
}

@WWW{log4j,
  title   = {Log4J V 1 Quellcode},
  url     = {https://github.com/apache/logging-log4j1/tree/b7e9154128cd4ae1244c877a6fda8f834a0f2247/src},
  urldate = {2022-04-05},
}

@Comment{jabref-meta: databaseType:biblatex;}
